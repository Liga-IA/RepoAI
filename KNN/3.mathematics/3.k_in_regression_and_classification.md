# English Version

## "k" in Regression and Classification

As explained in [How to determine the value of k](../1.concepts/3.How_to_determine_the_value_of_K.md), we have the following characteristics of k:

-	k, when small, tends to cause overfitting
-	k, when large, tends to cause underfitting
-	k, when even, can lead to ties in classification problems and, consequently, inaccuracies.

When choosing the best value, we can use the square root of the number of available data points as a starting point. However, a more accurate way to make this decision is to use cross-validation techniques!

But now, let’s better understand the math behind these characteristics!

To understand whether k is large or small, we need to talk about the concepts of **error**, **bias**, and **variance**.

### Error
We can calculate the error produced by a model in more than one way. However, here we’ve chosen one for regression, and one for classification.

#### Error in regression
For regression, the total error can be calculated using the "Mean Squared Error" (already discussed in Linear Regression – link to page), whose formula is:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

That is:
-	$\text{MSE}$ stands for Mean Squared Error
-	$n$ is the total number of data points
-	$y_i$ is the actual value of the $i$-th data point
-	$\hat{y}_i$ is the predicted value for the $i$-th data point
-	$(y_i - \hat{y}_i)^2$ is the squared difference between the actual and predicted values, giving more weight to larger errors

#### Error in classification

For classification, we can calculate the error rate as follows:

$$
\text{Error Rate} = \frac{\text{Number of incorrect predictions}}{\text{Total number of samples}}
$$

> [!NOTE]
> In all models, no matter how good they are, there will always be an error associated with their predictions. This component of the error, which cannot be eliminated, is called the irreducible error. The previous formulas compute the total error, which includes—among other factors—the irreducible error, as we’ll see later.

### Bias

Bias occurs when a model is too simple to capture the true behavior of the data.
-	In linear regression, for example, it’s like trying to fit a straight line to data that follows a curved pattern.
-	In k NN, it means over smoothing the model so it misses local patterns. This happens when we pick very large values of kkk, because the prediction is based on too many neighbors.
  
**large k** → **high bias** → **underfitting**

> Therefore, we can understand bias via the same example used in “Underfitting and high k values” in the conceptual section: [How to determine the value of k](../1.concepts/3.How_to_determine_the_value_of_K.md).

### Variance

Variance refers to how much the model’s predictions would change if it were trained on a different dataset.

-	In other words, with high variance, adding or removing a single point can drastically change the prediction.
-	This happens when we pick very small values of k, since the prediction relies on too few neighbors.
  
**small k** → **high variance** → **overfitting**
> Therefore, we can understand variance via the same example used in “Overfitting and low k values” in the conceptual section: [How to determine the value of k](../1.concepts/3.How_to_determine_the_value_of_K.md).

### Relationship between Error, Bias, and Variance

#### Regression
It is possible to state that the MSE - that is, the total error - can be represented as:

$$
TotalError=Bias² + Variance + IrreducibleError
$$

#### Classification
The idea that there is a relationship between the total error and the irreducible error, bias, and variance remains. However, the decomposition of the total error in terms of these other concepts is not done in such a direct way.

> [!TIP] To find the best k, we must find the minimum value of the total error. Remembering that, when k increases:
> - Bias increases
> - Variance decreases
> - Irreducible error remains constant

## Cross-validation

For a more precise calculation of k, we use cross-validation.

Basically, when we evaluate a model, we calculate the training error (which is calculated based on the data used to train the model), and we also calculate the test error (which is calculated based on new data).

Therefore, we do cross-validation:
1.	We choose a value for k.
2.	We divide the data into subsets.
3.	For the chosen value of k, we train the data on the chosen subset and test on the ones that were not chosen.
4.	Calculate the error for the chosen k. Repeat the process until it has been done for several values of k.
5.	Choose the k based on the one that resulted in the lowest error.

## References
JAMES, Gareth et al. An introduction to statistical learning: with applications in Python. New York: Springer, 2023.

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. The elements of statistical learning: data mining, inference, and prediction. 2. ed. New York: Springer, 2009.

## Colaborators
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) | 
| :---: | 

# Portuguese Version

## "k" em Regressão e Classificação

Como explicado em [Como determinar o valor de k](../1.concepts/3.How_to_determine_the_value_of_K.md), temos as seguintes características de k:
- k, quando pequeno, tende a gerar overfitting
- k, quando grande, tende a gerar underfitting
- k, quando par, pode gerar empates nos problemas de classificação e, consequentemente, imprecisões.

Ao escolhermos o melhor valor, podemos utilizar como ponto de partida a raiz quadrada do número de dados disponíveis. No entanto, uma forma mais assertiva para essa decisão é utilizar técnicas de validação cruzada!

Mas, agora, vamos entender melhor a matemática por trás dessas características!

Para entendermos se k é grande ou pequeno, precisamos abordar os conceitos de **erro**, **viés** e **variância**.

### Erro

Podemos calcular o erro produzido por um modelo de mais de uma forma. No entanto, aqui foi escolhida uma forma para regressão, e uma para classificação.

#### Erro em regressão
Para regressão, o erro total pode ser calculado por meio do "Erro Quadrático Médio" (já abordado em Regressao Linear - link para pagina), cuja fórmula é: 

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

Em que:
- $\text{MSE}$ é o erro quadrático médio (Mean Squared Error, em inglês)
- $n$ é o número total de amostras no conjunto de dados.  
- $y_i$ é o valor real observado da $i$-ésima amostra.  
- $\hat{y}_i$ é o valor predito pelo modelo para a $i$-ésima amostra.  
- $(y_i - \hat{y}_i)^2$ é o erro ao quadrado da $i$-ésima amostra, que penaliza mais fortemente discrepâncias maiores.  

#### Erro em classificação
Para classificação, podemos calcular a taxa de erro da seguinte maneira:

$$
\text{Taxa de Erro} = \frac{\text{Número de previsões incorretas}}{\text{Número total de amostras}}
$$

> [!NOTE]
> Em todos os modelos, não importa o quão bons eles sejam, sempre haverá um erro associado às previsões. Esse componente do erro, que não pode ser eliminado, é chamado de erro irredutível. As fórmulas anteriores calculam o erro total, que engloba - dentre outros fatores - o erro irredutível, como veremos mais adiante.

### Viés
É quando um modelo é um muito simples para captar o comportamento real dos dados.

Em regressão linear, por exemplo, seria como tentar representar um padrão curvo com uma reta.
No contexto de KNN, seria generalizar o modelo de tal forma que ele não capta padrões locais. Isto ocorre quando usamos valores de k muito grandes, já que está considerando muitos vizinhos para chegar a uma resposta.

**alto k** -> **alto viés** -> **underfitting**

> Portanto, podemos entender o viés por meio do mesmo exemplo utilizado em "Underfitting e valores altos de k" na parte conceitual: [Como determinar o valor de k](../1.concepts/3.How_to_determine_the_value_of_K.md).

### Variância
Se refere a quanto as previsões do modelo mudariam caso fosse treinado com outro conjunto de dados. 

Ou seja, quando há alta variância, se adicionarmos ou removermos um ponto, é possível que a predição mude drasticamente. Isto ocorre quando usamos valores de k muito pequenos, já que está considerando poucos vizinhos para chegar a uma resposta.

**baixo k** -> **alta variância** -> **overfitting**

> Portanto, podemos entender a variância por meio do mesmo exemplo utilizado em "Overfitting e valores baixos de k" na parte conceitual: [Como determinar o valor de k](../1.concepts/3.How_to_determine_the_value_of_K.md).

### Relação entre Erro, Viés e Variância

#### Regressão
É possível afirmar que, o MSE - isto é, o erro total - pode ser representado como:

$$
Erro Total = Viés² + Variância + Erro Irredutível
$$

#### Classificação
A ideia de que há relação entre o erro total com o erro irredutível, viés e variância se mantém. No entanto, a decomposição do erro total em termos desses outros conceitos não é feita de forma tão direta.

>[!TIP]
> Para encontrarmos o melhor k, devemos encontrar o valor mínimo do erro total. Lembrando que, quando k aumenta:
> - O viés aumenta
> - A variância diminui
> - O erro irredutível permanece constante

## Validação cruzada
Para o cálculo mais preciso de k, utilizamos a validação cruzada.

Basicamente, quando avaliamos um modelo, calculamos o **erro de treinamento** (que é calculado com base nos dados utilizados para treinarmos o modelo), e, também, calculamos o **erro de teste** (que é calculado com base em novos dados).

Por isso, fazemos validação cruzada: 
1. Escolhemos um valor para k.
2. Dividimos os dados em subconjuntos.
3. Para o valor de k, treinamos os dados no subconjunto escolhido e testo nos que não foram escolhidos.
4. Calcula o erro para o k escolhido. Repete o processo até ter feito para vários valores de k.
5. Escolhe o k com base no que resultou em menor erro.

## Referências
JAMES, Gareth et al. An introduction to statistical learning: with applications in Python. New York: Springer, 2023.

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. The elements of statistical learning: data mining, inference, and prediction. 2. ed. New York: Springer, 2009.

## Colaboradores
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) | 
| :---: | 
