# English Version

As previously explained in: *link*, the nearest neighbor method is commonly used to find media similar to the one being searched. For example, the recommendation systems of platforms such as Netflix and Spotify use this technique to suggest content similar to what the user has shown interest in.

However, in order for these recommendation systems to be fast and efficient, the approximate nearest neighbor method is employed. Below, we explore the difference between the exact nearest neighbor** method and the approximate nearest neighbor method.

## Exact Nearest Neighbor:

This algorithm compares the input with all available data points and finds the one that is closest—that is, the one with the smallest distance. In this case, the computational cost is proportional to the number of existing data points. This process is known as exhaustive search or brute-force search in the context of algorithms.

Therefore, it becomes evident that for very large datasets—such as those used by the platforms mentioned earlier—this technique can be extremely time-consuming and require a high amount of computational resources.

As such, the approximate nearest neighbor algorithm becomes more efficient and practical, especially when dealing with large and/or high-dimensional datasets.

## Approximate Nearest Neighbor:

This algorithm seeks a data point that is sufficiently close to the query point, though not necessarily the closest of all. Thus, this approach proves to be quite effective in the previously mentioned scenario, since recommendations that are merely similar to the user’s interests and searches are usually enough to spark interest in new media.

The implementation of this algorithm involves several stages:

- Dimensionality Reduction: Reducing of the dimensionality of the data is essential for making the model more efficient, as it simplifies and speeds up the data analysis process.

- Vector Encoding: After reducing the dimensionality and storing the dataset as vectors, those vectors can be encoded—i.e., transformed into more compact structures—using different data structures such as Trees, LSH, or Quantization, to improve search efficiency.

- Search: Finally, the search method is implemented, and it may vary depending on the data structure used.


# Portuguese Version

Como explicado anteriormente em: *link* , o método do vizinho próximo é comumente utilizado para encontrar midías semelhantes àquelas pesquisadas. Como exemplo, o sistema de recomendação de plataformas como Netflix e Spotify utilizam desse recurso para recomendar ao usuário mídias semelhantes a de interesse pesquisado por ele.
No entanto, para que esse sistema de recomendação seja rápido e eficiente utiliza-se o método do vizinho mais proximo aproximado. A seguir, podemos entender melhor a diferença entre o método do vizinho mais próximo exato e o método do vizinho mais próximo aproximado.

## Vizinho mais proximo exato:

Esse algoritmo compara uma entrada com todos os pontos de dados disponíveis e encontra aquele mais próximo, ou seja, com a menor distância. Nesse caso, o custo computacional é proporcional ao número de dados existentes. Tal processo é conhecido como busca exaustiva ou busca por força bruta no contexto de algoritmos. 
Sendo assim, fica evidente que para um conjuno de dados muito grande, como o das plataformas exemplificadas anteriormente, essa técnica pode ser muito demorada e necessitar de uma quantidade de processamento muito alta.

  
Desse modo, o algoritmo do vizinho mais próximo aproximado se torna mais eficiente e útil, tendo em vista um conjunto de dados muito grande e/ou com muitas dimensões. 

## Vizinho mais proximo aproximado:

Nesse algoritmo, busca-se um ponto no conjunto de dados que esteja suficientemente próximo do dado fornecido, não sendo, necessariamente, o mais próximo de todos. Sendo assim, essa abordagem é bastante eficaz para o caso exemplificado anteriormente, uma vez que recomendações similares aos interesses e buscas do usuário geralmente são suficientes para despertar seu interesse por novas mídias.

A implementação desse algoritmo se da em algumas etapas:

- Redução de dimensionalidade: a redução da dimensão dos dados é fundamental para que o modelo seja mais eficiente, visto que a analise dos dados se torna mais simples e rápida.
  
- Codificação vetorial: após reduzir a dimensão do conjunto de dados e armazená-los em um vetor, para tornar a busca mais rápida e eficiente, pode-se codificar o vetor,ou seja, transformá-lo em uma estrutura mais compacta, através de diferentes estruturas de dados, como Árvores, LHS e Quantização.
  
- Busca: por fim, implementa-se o método de busca. Esse método pode depender da estrutura de dados utilizada.

## References

Compreendendo o algoritmo de vizinho mais próximo aproximado (ANN). (2024, April 17). Elastic Blog. https://www.elastic.co/pt/blog/understanding-ann

(N.d.). Towardsdatascience.com. Retrieved May 4, 2025, from https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6/?source=post_page-----7e2c6f0778bc---------------------------------------



