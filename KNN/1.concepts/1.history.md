# English version

## Introduction ##
  K-Nearest Neighbor is a supervised machine learning model, meaning it learns from labeled data consisting of inputs (x) and their corresponding desired outputs (y). This model is employed for predicting both categorical and numerical data, utilizing an instance-based learning approach. This approach involves storing the training data, subsequently, when a new instance is presented, a set of related, similar instances is retrieved from memory and used to classify the novel query instance.

  In the k-Nearest Neighbor (k-NN) model, each data instance is represented as a point in a feature space. New instances are classified based on their proximity to instances in the training set, using a similarity measure. In this way, the prediction is made by considering the k nearest neighbors.

## History ##
  The k-Nearest Neighbor (k-NN) algorithm originated in the 1950s, initially proposed by Evelyn Fix and Joseph Hodges in a theoretical work presented as *Technical Report No. 21* at the University of California, Berkeley, in 1951. Years later, during the 1960s, the algorithm was refined and formally developed by Thomas M. Cover and Peter E. Hart in their 1967 paper *"Nearest Neighbor Pattern Classification."*.

## References
FIX, Evelyn; HODGES Jr., Joseph L. Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties. Berkeley: University of California, 1951. (Technical Report n¬∫ 21).

COVER, Thomas M.; HART, Peter E. Nearest Neighbor Pattern Classification. IEEE Transactions on Information Theory, 1967. 

Halder, R.K., Uddin, M.N., Uddin, M.A. et al. Enhancing K-nearest neighbor algorithm: a comprehensive review and performance analysis of modifications. J Big Data 11, 113 (2024). 

## üëæ **Contributors**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) |
| :---: | :---: |

## **License**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modify, and share at will! ‚úåÔ∏è

# Portuguese version

## Introdu√ß√£o ##

O K-Vizinhos Mais Pr√≥ximos (k-Nearest Neighbor, ou k-NN) √© um modelo de aprendizado de m√°quina supervisionado, o que significa que ele aprende a partir de dados rotulados, compostos por entradas (x) e suas respectivas sa√≠das desejadas (y). Esse modelo √© utilizado para prever tanto dados categ√≥ricos quanto num√©ricos, empregando uma abordagem de aprendizado baseado em inst√¢ncias. Essa abordagem envolve o armazenamento dos dados de treinamento, posteriormente, quando uma nova inst√¢ncia √© apresentada, um conjunto de inst√¢ncias semelhantes √© recuperado da mem√≥ria e utilizado para classificar a nova inst√¢ncia de consulta.

No modelo k-Vizinhos Mais Pr√≥ximos (k-NN), cada inst√¢ncia de dados √© representada como um ponto em um espa√ßo de caracter√≠sticas. Novas inst√¢ncias s√£o classificadas com base em sua proximidade com inst√¢ncias do conjunto de treinamento, utilizando uma medida de similaridade. Dessa forma, a predi√ß√£o √© feita considerando os k vizinhos mais pr√≥ximos.

## Hist√≥rico ##

O algoritmo k-Vizinhos Mais Pr√≥ximos (k-NN) surgiu na d√©cada de 1950, proposto inicialmente por Evelyn Fix e Joseph Hodges em um trabalho te√≥rico apresentado como *Technical Report No. 21* na Universidade da Calif√≥rnia, Berkeley, em 1951. Anos depois, durante a d√©cada de 1960, o algoritmo foi refinado e formalmente desenvolvido por Thomas M. Cover e Peter E. Hart em seu artigo de 1967, intitulado *"Nearest Neighbor Pattern Classification"*.

## Refer√™ncias ##
FIX, Evelyn; HODGES Jr., Joseph L. Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties. Berkeley: University of California, 1951. (Technical Report n¬∫ 21).

COVER, Thomas M.; HART, Peter E. Nearest Neighbor Pattern Classification. IEEE Transactions on Information Theory, 1967. 

Halder, R.K., Uddin, M.N., Uddin, M.A. et al. Enhancing K-nearest neighbor algorithm: a comprehensive review and performance analysis of modifications. J Big Data 11, 113 (2024). 

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) |
| :---: | :---: |

## **Licen√ßa**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modifique e compartilhe √† vontade! ‚úåÔ∏è
