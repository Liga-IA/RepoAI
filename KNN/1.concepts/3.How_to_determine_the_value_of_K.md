# English version

## How to define the value of k?
At this point, it is clear that the accuracy of the k-NN algorithm directly depends on the choice of the value of k, but this decision is not straightforward. Defining the value of k requires a balance: very low values only consider the nearest neighbors, losing generalization, while very high values may overly smooth the model, causing the loss of important features in the data. Therefore, when choosing k, it is essential to consider the possible values and common errors associated with each, as outlined below.

### Overfitting and low values of k
*Overfitting* occurs when a model becomes excessively tuned to the training data, capturing even the noise and specific variations within the data. As a result, when the model is applied to test data, it generates inaccurate predictions because it tends to apply patterns specific to the training data to the new data, rather than seeking general patterns that can be applied to all data.
In the case of the k-NN algorithm, choosing a low value for k can lead to overfitting because the model only considers the nearest neighbors, affecting its ability to generalize. In summary, it analyzes what is extremely close, without considering the "context."
> For example, in a dataset with two classes, red and blue balls, if a new ball is added closer to a red ball but with 3 blue balls slightly farther away, with k=1, it will be incorrectly classified as red due to its sensitivity to the nearest neighbor, while in reality, the correct classification would be blue.

### Underfitting and high values of k
On the other hand, *underfitting* occurs when a model is too simple and becomes overly generalized, losing the ability to identify specific and relevant features of the data. As a result, its predictions are also inaccurate. In this way, in the k-NN algorithm, a very high value for k can lead to underfitting, as too many neighbors are considered, losing the specificities of the new data.
> A simple example, still considering two dimensions and red and blue balls, if a ball is added closer to two blue balls and three more distant red balls, but with **k=5**, the new ball will be incorrectly classified as red, because it is the majority value, even though the new data is closer to the blue balls.

### The best value of k
From this point forward, it is important to choose a value for k that is not too sensitive to its neighbors to the point of failing to generalize, but also not excessively broad. The first recommendation is to choose an odd value for k in order to avoid possible ties, which would need to be resolved in some way, adding complexity and uncertainty to the algorithm.

A common strategy is to use the square root of the total number of instances in the dataset as a reference, since it will not be a value small enough to cause overfitting, but not so large as to generate underfitting.

Additionally, cross-validation techniques are recommended to help determine the ideal value of k. These techniques involve splitting the data into N smaller parts, using a specific value of k. The model is trained on N-1 parts and tested on the remaining part. This process is repeated N times, with each part serving as the test set in one of the executions. The model's efficiency is then calculated based on the average performance across all iterations. The same procedure is repeated for different values of k. The value of k that shows the best average performance is selected. This technique helps prevent both overfitting and underfitting, as it allows for evaluating the worst k values before ultimately using them.

***

# Portuguese version

## Como definir o valor de k?
Neste ponto, já é evidente que a precisão do algoritmo k-NN depende diretamente da escolha do valor de k, mas essa decisão não é tão simples. Para definir o valor de k, é preciso equilíbrio: valores muito baixos analisam apenas os vizinhos extremamente próximos, perdendo generalização, enquanto valores muito altos podem suavizar excessivamente o modelo, causando perda de caracteristicas importantes dos dados. Portanto, ao escolher k, é essencial considerar os possíveis valores e erros comuns relacionados a cada um, conforme apresentado a baixo.

### Overfitting e valores baixos de k
O *overfitting* acontece quando um modelo se ajusta excessivamente aos dados de treino, capturando até mesmo os ruídos dos dados e variações específicas deles. Dessa forma, ao aplicar o modelo a dados de teste, são geradas previsões imprecisas, pois ele tende a aplicar padrões específicos dos dados de treino aos novos dados, ao invés de buscar padrões gerais que possam ser aplicados a todos os dados.
No caso do algoritmo k-NN, a escolha de um valor baixo de k, pode levar ao overfitting, pois o modelo se torna relaciona apenas com os vizinhos mais próximos, afetando sua capacidade de generalização. Em resumo, ele analisa o que está extremamente perto, sem se preocupar com o "contexto".
> Por exemplo, se em um conjunto de dados com duas classes, bolas vermelhas e azuis, for adicionada uma nova bola mais próxima a uma vermelha, porém, com 3 azuis um pouco mais distantes, com ```k=1```, ela será incorretamente classificada como vermelha, devido à sensibilidade ao vizinho mais próximo, enquanto, na verdade, a classificação correta seria azul.

### Underfitting e valores altos de k
Já o *underfitting* ocorre quando um modelo é tão simples que se torna excessivamente generalizado, perdendo a capacidade de identificar caracteristicas especificas e relevantes dos dados. Como resultado, suas previsões também são imprecisas. Dessa maneira, no algoritmo k-NN, um número muito alto para k, pode gerar *underfitting*, pois um número muito alto de vizinhos é considerado, perdendo especificidades dos novos dados. 
> Um exemplo simples, ainda considerando duas dimensões e bolas vermelhas e azuis, se uma bola é adicionada mais próxima a duas azuis e outras 3 vermelhas mais distantes, mas ```k=5```, a nova bola será incorretamente classificada como vermelha, pois é o valor em maior quantidade, mesmo o novo dado sendo mais próximo ao azul.

## Melhor valor de k
Com isso em frente, é preciso escolher um valor de k que não seja tão sensível aos seus vizinhos ao ponto de não conseguir generalizar, mas também não seja excessivamente abrangente. A primeira recomendação  é escolher um valor ímpar para k, a fim de evitar possíveis empates, que devem ser decididos de alguma maneira, causando complexidade e incerteza ao algoritmo.

Uma estratégia comum é adotar como referência a raiz quadrada do número total de instâncias no conjunto de dados, pois não será um valor tão pequeno para ocasionar overfitting, mas nem tão grande para gerar underfitting.

Além disso, técnicas de validação cruzada são recomendadas para auxiliar na escolha do valor ideal de k. Essas técnicas consistem em dividir os dados em N partes menores, com um valor específico de k. O modelo é treinado em N-1 partes e testado na parte restante. Esse processo é repetido N vezes, com cada parte sendo utilizada como conjunto de teste em uma das execuções. A eficiência do modelo é então calculada com base na média de desempenho em todas as iterações. O mesmo procedimento é repetido para diferentes valores de k. O valor de k que apresentar a melhor média de desempenho é o escolhido. Essa técnica ajuda a evitar tanto o overfitting quanto o underfitting, pois permite avaliar previamente os piores valores de k, antes de utilizá-los de forma definitiva.