# English version

## How to define the value of k?
The choice of k directly impacts the accuracy of the k-NN algorithm, but this decision is not straightforward. Selecting the right value of k requires balance: very low values only consider extremely close neighbors, resulting in poor generalization, while very high values can oversimplify the model, ignoring important patterns in the data. Therefore, it is essential to consider common errors associated with different k values, as discussed below.

### Overfitting and low values of k
**Overfitting** occurs when a model fits the training data too closely, capturing even noise and specific variations that do not generalize well. This leads to inaccurate predictions on new data, as the model becomes overly sensitive to atypical points, known as outliers.

In the k-NN algorithm, choosing a very low value for k can lead to overfitting, since the model will only consider the nearest neighbors, which may include outliers. As a result, the algorithm's accuracy may be negatively affected.

> For example, imagine a dataset with two separated classes, A and B, but with a point from class A inserted into class B ‚Äî in other words, an outlier. If a new point is added to class B, but extremely close to the outlier, then with k=1, it will be incorrectly classified as belonging to class A due to the sensitivity to the nearest neighbor. This example is illustrated in the figures below: the first shows the location of the new data point (in blue), and the second shows its incorrect classification when using k=1.

**Figure 1: Insertion of a new data point**

<img src="./img/overfitting_example.png" alt="Overfitting example" width="300"/>

**Figure 2: Classification of the new data point**

<img src="./img/overfitting_exemplo2.png" alt="Overfitting example" width="300"/>

### Underfitting and high values of k
**Underfitting** occurs when a model is too simple and becomes overly generalized, losing the ability to identify specific and relevant features of the data. As a result, its predictions are also inaccurate.

In this way, in the k-NN algorithm, a very high number for k can lead to underfitting, because too many neighbors are considered, losing the specifics of the new data.

> As another example, consider again two well-defined classes, A and B, with a total of 20 training data points, where class B contains 14 points. If a new point is inserted in the center of class A‚Äôs region and `k=20`, the model will consider many neighbors, most of which will likely belong to class B, since it represents the majority of the dataset. This results in the incorrect classification of the new point as a member of class B, illustrating the model's excessive triviality. This example is shown in a simplified form in the figures below.

**Figure 3: Insertion of a new data point**  

<img src="./img/underfitting_ex1.png" alt="Underfitting example" width="300"/>

**Figure 4: Classification of the new data point**  

<img src="./img/underfitting_ex2.png" alt="Underfitting example 2" width="300"/>

### Even Values of k
Consider a dataset with two distinct classes, A and B. Also, assume that the value of k is practically ideal, meaning it is balanced enough to avoid both overfitting and underfitting. However, suppose that k is an even number. In the case of a tie when analyzing the majority of neighbors near a new data point, the model is forced to arbitrarily choose a class for the point. This makes the result inaccurate, even if tie-breaking criteria are implemented, because the choice will not always truly reflect the reality of the data. Therefore, it is recommended to set an odd value for k to avoid this situation.

> Imagine that in this dataset, `k=4` and the tie-breaking criterion is to classify the new data point based on the class of its nearest neighbor. If a new point is added such that half of its closest neighbors belong to class A and the other half to class B, a tie will occur. In that case, the class of the new point will be determined by its nearest neighbor. However, if that neighbor is an outlier from class A located within class B's region, the point will be incorrectly classified as a member of class A, even though it is closer to class B‚Äôs region. This can be seen in the figures below.

**Figure 5: Insertion of a new data point**  

<img src="./img/even_k_ex1.png" alt="Even k example" width="300"/>

**Figure 6: Classification of the new data point**  

<img src="./img/even_k_ex2.png" alt="Even k example 2" width="300"/>

### The best value of k
Given the potential issues arising from the choice of k, it is essential to define a value that is not so sensitive to its neighbors that it fails to generalize, but also not so broad that it ignores relevant patterns. Additionally, choosing an odd value for k is equally essential to avoid possible ties when analyzing the majority of the nearest neighbors.

A common strategy for selecting k is to use the square root of the total number of data points in the dataset, as this value will not be too small to cause overfitting, nor too large to cause underfitting. If the resulting value is even, it is recommended to adjust it to the nearest odd number in order to avoid ties. Furthermore, the use of cross-validation is recommended to help in selecting the ideal value for k, as it allows for a preemptive evaluation of the worst k values, thus preventing both overfitting and underfitting.

<details>
  <summary><strong>What are cross-validation techniques?</strong></summary>
  Cross-validation techniques involve dividing the data into N smaller parts, with a specific value of k. The model is trained on N-1 parts and tested on the remaining part, repeating this process N times, using each part as the test set once. The model's efficiency is then calculated based on the average performance across all runs. The same procedure is repeated for different values of k. The value of k that shows the best average performance is chosen
</details>

## References
**IBM.** _K-nearest neighbors (KNN)_. Dispon√≠vel em: https://www.ibm.com/think/topics/knn. Acesso em: 21 de abril de 2025.
**FERREIRA, E.** _Cross-Validation_. Universidade Federal do Paran√°. Dispon√≠vel em: http://www.leg.ufpr.br/~eferreira/CE064/ency-cross-validation.pdf. Acesso em: 27 de abril de 2025.
**MARIZ, Filipe Mendes.** _Avalia√ß√£o e compara√ß√£o de vers√µes modificadas do algoritmo KNN_. 2017. [s.l.], Universidade Federal de Pernambuco, Centro de Inform√°tica, 2017. Dispon√≠vel em: https://www.cin.ufpe.br/~tg/2017-2/fmm4-tg.pdf. Acesso em: 23 de abril de 2025.
**SINGH, Manjeet; SINGH, Gurpreet.** _A Survey of kNN Algorithm_. 2018. Dispon√≠vel em: https://www.researchgate.net/publication/348305327_A_Survey_of_kNN_Algorithm. Acesso em: 23 de abril de 2025.

## üëæ **Contributors**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) |
| :---: |

## **License**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modify, and share at will! ‚úåÔ∏è

****

# Portuguese version

## Como definir o valor de k?
A escolha do valor de k afeta diretamente a precis√£o do algoritmo k-NN, mas essa decis√£o n√£o √© t√£o simples. Para definir o valor de k, √© preciso equil√≠brio: valores muito baixos analisam apenas os vizinhos extremamente pr√≥ximos, perdendo generaliza√ß√£o, enquanto valores muito altos podem trivializar o modelo, causando perda de caracteristicas importantes dos dados. Portanto, ao escolher k, √© essencial considerar erros comuns relacionados a cada escolha de valor de k, conforme apresentado a baixo.

### Overfitting e valores baixos de k
O **overfitting** ocorre quando um modelo se ajusta demais aos dados de treino, capturando at√© mesmo os ru√≠dos e varia√ß√µes espec√≠ficas deles. Isso resulta em previs√µes imprecisas para novos dados, pois o modelo se torna extrememante sens√≠vel a pontos fora do padr√£o, chamados de outliers.

No algoritmo k-NN, a escolha de um valor muito baixo de k, pode levar ao overfitting, pois o modelo ir√° considerar apenas os vizinhos mais pr√≥ximos, que podem incluir outliers. Assim, a precis√£o do algoritmo pode ser afetada.

> Por exemplo, imagine um conjunto de dados com duas classes separadas, A e B, mas Vcom um ponto da classe A inserido na classe B, isto √©, um outlier. Se for adicionado um novo ponto √† classe B, por√©m, extremamente pr√≥ximo do outlier, com ```k=1```, ele ser√° incorretamente classificado como A, devido √† sensibilidade ao vizinho mais pr√≥ximo. Este exemplo √© mostrado nas figuras abaixo, em que a primeira mostra a localiza√ß√£o do novo dado (azul) e a segunda, a classifica√ß√£o incorreta dele, para k=1.

**Figura 1: Inser√ß√£o de um novo dado.**        

<img src="./img/overfitting_example.png" alt="Exemplo de overfitting" width="300"/>


**Figura 2: Classifica√ß√£o do novo dado**

<img src="./img/overfitting_exemplo2.png" alt="Exemplo de overfitting" width="300"/>

### Underfitting e valores altos de k
J√° o **underfitting** ocorre quando um modelo √© t√£o simples que se torna excessivamente generalizado, perdendo a capacidade de identificar caracteristicas especificas e relevantes dos dados. Como resultado, suas previs√µes tamb√©m s√£o imprecisas.

Dessa maneira, no algoritmo k-NN, um n√∫mero muito alto para k, pode gerar underfitting, pois um n√∫mero muito alto de vizinhos √© considerado, perdendo especificidades dos novos dados. 

> Exemplificando, considere novamente duas classes bem definidas, A e B, com 20 dados de treinamento no total, sendo que a classe B possui 14 dados. Se um novo ponto for inserido no centro da regi√£o da classe A e ```k=20```, o modelo ir√° considerar muitos vizinhos, os quais, a maioria, provavelmente ser√° da classe B uma vez que esta classe representa quase todo o conjunto. Isso resulta na classifica√ß√£o incorreta do novo dado como membro da classe B, o que demonstra a trivialidade excessiva do modelo. Este exemplo √© mostrado de forma reduzida nas figuras abaixo.

**Figura 3: Inser√ß√£o de um novo dado.**      

<img src="./img/underfitting_ex1.png" alt="Exemplo de underfitting" width="300"/>

**Figura 4: Classifica√ß√£o do novo dado.**          

<img src="./img/underfitting_ex2.png" alt="Exemplo de underfitting" width="300"/>

### Valores pares de k
Considere um conjunto de dados com duas classes distintas, A e B. Considere, tamb√©m, que o valor de k seja praticamente ideal, ou seja, equilibrado ao ponto de n√£o causar overfitting ou underfitting. Contudo, suponha que k √© um valor par. Caso haja empate ao analisar a maioria dos vizinhos pr√≥ximos √† um novo dado, o modelo √© for√ßado a escolher arbitrariamente uma classe para o ponto. Isso torna o resultado impreciso, mesmo que seja implementado crit√©rios para a decis√£o de empates, pois a escolha nem sempre representar√° verdadeiramente a realidade dos dados. Dessa forma, √© recomendado definir um valor √≠mpar de k para evitar esta situa√ß√£o.

> Imagine que neste conjunto, ```k=4``` e que o crit√©rio de desempate √© classificar o novo dado com base na classe de seu vizinho mais pr√≥ximo. Se um novo ponto for adicionado de forma que metade de seus vizinhos mais pr√≥ximos sejam da classe A e a outra metade da classe B, ser√° gerado um empate. Ent√£o, a classe do novo dado ser√° definiada pelo seu vizinho mais pr√≥ximo. Entretanto, se esse vizinho for um outlier da classe A, localizado na regi√£o da classe B, o dado ser√° classificado incorretamente como membro da classe A, mesmo estando mais pr√≥ximo da regi√£o da classe B. Isso √© visto nas figuras abaixos.


**Figura 5: Inser√ß√£o de um novo dado.**       

<img src="./img/even_k_ex1.png" alt="Exemplo de k par" width="300"/>

**Figura 6: Classifica√ß√£o do novo dado.**     

<img src="./img/even_k_ex1.png" alt="Exemplo 2 de k par" width="300"/>


## Melhor valor de k
Tendo em vista os poss√≠veis problemas decorrentes da escolha de k, √© essencial definir um valor em que ele que n√£o seja t√£o sens√≠vel aos seus vizinhos ao ponto de n√£o conseguir generalizar, mas tamb√©m n√£o seja extremamente abrangente ao ponto de ignorar padr√µes relevantes. Al√©m disso, optar por um valor √≠mpar de k √© igualmente essencial, a fim de evitar poss√≠veis empates ao analisar a maioria dos vizinhos mais pr√≥ximos.

Uma estrat√©gia comum para a escolha de k √© utilizar a raiz quadrada do n√∫mero total de dados do conjunto, pois n√£o ser√° um valor t√£o pequeno para ocasionar overfitting, mas nem t√£o grande para gerar underfitting. Caso o valor obtido seja par, √© indicado ajust√°-lo para o valor √≠mpar pr√≥ximo, a fim de evitar empates. Al√©m disso, o uso de valida√ß√£o cruzada √© recomendado para auxiliar na escolha do valor ideal de k, pois permite avaliar previamente os piores valores de k, evitando overfitting e underfitting.

<details>
  <summary><strong>O que s√£o t√©cnicas de valida√ß√£o de cruzada?</strong></summary>
  T√©cnicas de valida√ß√£o cruzadas consistem em dividir os dados em N partes menores, com um valor espec√≠fico de k. O modelo √© treinado em N-1 partes e testado na parte restante, repetindo esse processo N vezes, utilizando cada parte como conjunto de teste uma vez. A efici√™ncia do modelo √©, ent√£o, calculada com base na m√©dia de desempenho de todas as execu√ß√µes. O mesmo procedimento √© refeito para diferentes valores de k. O valor de k que apresentar a melhor m√©dia de desempenho √© o escolhido.
</details>

### Refer√™ncias
**IBM.** _K-nearest neighbors (KNN)_. Dispon√≠vel em: https://www.ibm.com/think/topics/knn. Acesso em: 21 de abril de 2025.
**FERREIRA, E.** _Cross-Validation_. Universidade Federal do Paran√°. Dispon√≠vel em: http://www.leg.ufpr.br/~eferreira/CE064/ency-cross-validation.pdf. Acesso em: 27 de abril de 2025.
**MARIZ, Filipe Mendes.** _Avalia√ß√£o e compara√ß√£o de vers√µes modificadas do algoritmo KNN_. 2017. [s.l.], Universidade Federal de Pernambuco, Centro de Inform√°tica, 2017. Dispon√≠vel em: https://www.cin.ufpe.br/~tg/2017-2/fmm4-tg.pdf. Acesso em: 23 de abril de 2025.
**SINGH, Manjeet; SINGH, Gurpreet.** _A Survey of kNN Algorithm_. 2018. Dispon√≠vel em: https://www.researchgate.net/publication/348305327_A_Survey_of_kNN_Algorithm. Acesso em: 23 de abril de 2025.

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | 
| :---: |

## **Licen√ßa**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modifique e compartilhe √† vontade! ‚úåÔ∏è
