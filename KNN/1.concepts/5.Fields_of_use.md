# English version

The k-NN algorithm is widely used due to its various advantages. Among its main strengths are:

* **Easy to set up:** it only requires a distance metric and the value of k to operate;
* **Adaptability to new data:** the model easily adjusts to new data without the need for retraining;
* **Simplicity and effectiveness:** it is easy to understand and implement, while still delivering strong results in many scenarios.


For these reasons, the k-NN algorithm is applied across a wide range of fields. Below are some of its main areas of application:

### Recommendation mechanisms:
A very common application of the k-NN algorithm is the recommendation of content similar to what users consume. This is done using click data on websites or applications, where users are grouped into different clusters (classifications) to receive personalized approaches.
> You've probably seen this in some apps! The phrase "If you liked this, how about this?" is a strong indication that the application might be using the k-NN method.

### Pattern recognition:
k-NN has been widely used for pattern recognition, especially in text and digit classification. In the case of texts, the algorithm identifies the similarity between new documents and those already analyzed, with the goal of classifying them into specific categories. For digit recognition, such as handwriting recognition, k-NN is used to compare images of digits with known examples. In this way, the new data is classified based on its nearest neighbors.

### Image or video similarity:
Based on natural language descriptions of images and videos, the k-NN algorithm is used to find media similar to the searched ones, whether in images, videos, or texts.
> When you perform a similarity search, the results found satisfactorily are likely achieved thanks to the use of the k-NN method!

### Data Preprocessing:
Datasets often contain missing values, which can compromise the quality of the analysis. The k-NN algorithm can be used to estimate these missing values through a process known as data imputation. In this approach, the missing value is predicted based on the k nearest instances that have the value available. This allows the gap to be filled in a consistent way, preserving the overall pattern of the dataset.

### Healthcare:
In the healthcare field, the k-NN algorithm can be applied in various research areas, including genetic studies. It allows predicting the probability of hereditary conditions by comparing an individual's genetic profile with others already known, searching for patterns that may indicate the presence of genetic diseases. This way, genetic diseases can be detected early, speeding up diagnoses and treatments.

## References
**IBM.** _K-nearest neighbors (KNN)_. Dispon√≠vel em: https://www.ibm.com/think/topics/knn. Acesso em: 21 de abril de 2025.

## üëæ **Contributors**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) |
| :---: |

## **License**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modify, and share at will! ‚úåÔ∏è

***

# Portuguese version

O algoritmo k-NN √© amplamente utilizado gra√ßas √†s suas diversas vantagens. Entre os principais pontos positivos, destacam-se:
* **Simples de configurar:** requer apenas uma m√©trica de medida para calcular as dist√¢ncias e o valor de k;
* **Adaptabilidade a novos dados:** o modelo se ajusta facilmente a novos dados, sem precisar de novo treinamento para os novos dados;
* **Simplicidade e efic√°cia:** √© f√°cil de entender e implementar, al√©m de apresentar bons resultados em v√°rios cen√°rios.

Por essas raz√µes, o algoritmo k-NN √© aplicado nas mais diversas √°reas. A seguir, s√£o apresentados alguns desses campos de aplica√ß√£o:

### Mecanismos de recomenda√ß√µes: 
Uma aplica√ß√£o bastante comum do algoritmo k-NN, √© a recomenda√ß√£o de conte√∫dos semelhantes aos que os usu√°rios consomem. Isso √© feito a partir de dados de cliques em sites ou aplicativos, em que agrupam os usu√°rios em diferentes grupos (classifica√ß√µes) para receberem abordagens personalizadas.
> Voc√™ provavelmente j√° viu isso em alguns aplicativos! A frase "Se voc√™ gostou disso, que tal isso?" √© um forte indicativo de que a aplica√ß√£o pode estar usando o m√©todo k-NN.

### Reconhecimento de padr√µes:
O k-NN tem sido amplamente utilizado para reconhecer padr√µes, especialmente na classifica√ß√£o de textos e dig√≠tos. No caso de textos, o algoritmo identifica a semelhan√ßa entre novos documentos e aqueles j√° analisados, com o objetivo de classific√°-los em categorias espec√≠ficas. J√° para o reconhecimento de dig√≠tos, como no reconhecimento de escrita natural, o k-NN √© utilizado para comparar imagens de dig√≠tos com exemplos j√° conhecidos. Dessa forma, o novo dado √© classificado com base em seus vizinhos mais pr√≥ximos.

### Similaridade de imagens ou v√≠deos:
Com base na descri√ß√£o em linguagem natural de imagens e v√≠deos, o algoritmo k-NN √© usado para encontrar mid√≠as semelhantes √†quelas pesquisadas, seja em imagens, v√≠deos ou textos.
> Quando voc√™ pesquisa algo em buscas de similaridades, os resultados s√£o alcan√ßados de forma satisfat√≥ria, provavelmente, gra√ßas √† utiliza√ß√£o do m√©todo k-NN!

### Pr√©-processamento de dados:
Conjuntos de dados frequentemente apresentam valores ausentes, o que pode prejudicar a qualidade da an√°lise. O algoritmo k-NN pode ser utilizado para estimar esses falores, atrav√©s de processo conhecido como "inputa√ß√£o de dados". Nessa abordagem, o valor faltante √© estimado atrav√©s dos k exemplos mais pr√≥ximos que possuem esse valor preenchido. Isso permite completar a lacuna de forma coerente, mantendo o padr√£o do conjunto.

### Sa√∫de:
Na √°rea da sa√∫de, o algoritmo k-NN pode ser aplicado em diversas pesquisas, incluindo estudos gen√©ticos. Ele permite prever a probabilidade de condi√ß√µes heredit√°rias, comparando o perfil de gen√©tico de um indiv√≠duo com outros j√° conhecidos, em busca de padr√µes que possam indicar a presen√ßa de doen√ßas gen√©ticas. Dessa forma, √© poss√≠vel detectar precocemente doen√ßas gen√©ticas, agilizando os diagn√≥sticos e tratamentos.

### Refer√™ncias
**IBM.** _K-nearest neighbors (KNN)_. Dispon√≠vel em: https://www.ibm.com/think/topics/knn. Acesso em: 21 de abril de 2025.

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | 
| :---: |

## **Licen√ßa**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modifique e compartilhe √† vontade! ‚úåÔ∏è
