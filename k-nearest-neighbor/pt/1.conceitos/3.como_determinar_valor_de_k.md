## Como definir o valor de k?
A escolha do valor de k afeta diretamente a precis√£o do algoritmo k-NN, mas essa decis√£o n√£o √© t√£o simples. Para definir o valor de k, √© preciso equil√≠brio: valores muito baixos analisam apenas os vizinhos extremamente pr√≥ximos, perdendo generaliza√ß√£o, enquanto valores muito altos podem trivializar o modelo, causando perda de caracteristicas importantes dos dados. Portanto, ao escolher k, √© essencial considerar erros comuns relacionados a cada escolha de valor de k, conforme apresentado a baixo.

### Overfitting e valores baixos de k
O **overfitting** ocorre quando um modelo se ajusta demais aos dados de treino, capturando at√© mesmo os ru√≠dos e varia√ß√µes espec√≠ficas deles. Isso resulta em previs√µes imprecisas para novos dados, pois o modelo se torna extrememante sens√≠vel a pontos fora do padr√£o, chamados de outliers.

No algoritmo k-NN, a escolha de um valor muito baixo de k, pode levar ao overfitting, pois o modelo ir√° considerar apenas os vizinhos mais pr√≥ximos, que podem incluir outliers. Assim, a precis√£o do algoritmo pode ser afetada.

> Por exemplo, imagine um conjunto de dados com duas classes separadas, A e B, mas Vcom um ponto da classe A inserido na classe B, isto √©, um outlier. Se for adicionado um novo ponto √† classe B, por√©m, extremamente pr√≥ximo do outlier, com ```k=1```, ele ser√° incorretamente classificado como A, devido √† sensibilidade ao vizinho mais pr√≥ximo. Este exemplo √© mostrado nas figuras abaixo, em que a primeira mostra a localiza√ß√£o do novo dado (azul) e a segunda, a classifica√ß√£o incorreta dele, para k=1.

**Figura 1: Inser√ß√£o de um novo dado.**        

<img src="../../figures/overfitting_example.png" alt="Exemplo de overfitting" width="300"/>


**Figura 2: Classifica√ß√£o do novo dado**

<img src="../../figures/overfitting_exemplo2.png" alt="Exemplo de overfitting" width="300"/>

### Underfitting e valores altos de k
J√° o **underfitting** ocorre quando um modelo √© t√£o simples que se torna excessivamente generalizado, perdendo a capacidade de identificar caracteristicas especificas e relevantes dos dados. Como resultado, suas previs√µes tamb√©m s√£o imprecisas.

Dessa maneira, no algoritmo k-NN, um n√∫mero muito alto para k, pode gerar underfitting, pois um n√∫mero muito alto de vizinhos √© considerado, perdendo especificidades dos novos dados. 

> Exemplificando, considere novamente duas classes bem definidas, A e B, com 20 dados de treinamento no total, sendo que a classe B possui 14 dados. Se um novo ponto for inserido no centro da regi√£o da classe A e ```k=20```, o modelo ir√° considerar muitos vizinhos, os quais, a maioria, provavelmente ser√° da classe B uma vez que esta classe representa quase todo o conjunto. Isso resulta na classifica√ß√£o incorreta do novo dado como membro da classe B, o que demonstra a trivialidade excessiva do modelo. Este exemplo √© mostrado de forma reduzida nas figuras abaixo.

**Figura 3: Inser√ß√£o de um novo dado.**      

<img src="../../figures/underfitting_ex1.png" alt="Exemplo de underfitting" width="300"/>

**Figura 4: Classifica√ß√£o do novo dado.**          

<img src="../../figures/underfitting_ex2.png" alt="Exemplo de underfitting" width="300"/>

### Valores pares de k
Considere um conjunto de dados com duas classes distintas, A e B. Considere, tamb√©m, que o valor de k seja praticamente ideal, ou seja, equilibrado ao ponto de n√£o causar overfitting ou underfitting. Contudo, suponha que k √© um valor par. Caso haja empate ao analisar a maioria dos vizinhos pr√≥ximos √† um novo dado, o modelo √© for√ßado a escolher arbitrariamente uma classe para o ponto. Isso torna o resultado impreciso, mesmo que seja implementado crit√©rios para a decis√£o de empates, pois a escolha nem sempre representar√° verdadeiramente a realidade dos dados. Dessa forma, √© recomendado definir um valor √≠mpar de k para evitar esta situa√ß√£o.

> Imagine que neste conjunto, ```k=4``` e que o crit√©rio de desempate √© classificar o novo dado com base na classe de seu vizinho mais pr√≥ximo. Se um novo ponto for adicionado de forma que metade de seus vizinhos mais pr√≥ximos sejam da classe A e a outra metade da classe B, ser√° gerado um empate. Ent√£o, a classe do novo dado ser√° definiada pelo seu vizinho mais pr√≥ximo. Entretanto, se esse vizinho for um outlier da classe A, localizado na regi√£o da classe B, o dado ser√° classificado incorretamente como membro da classe A, mesmo estando mais pr√≥ximo da regi√£o da classe B. Isso √© visto nas figuras abaixos.


**Figura 5: Inser√ß√£o de um novo dado.**       

<img src="../../figures/even_k_ex1.png" alt="Exemplo de k par" width="300"/>

**Figura 6: Classifica√ß√£o do novo dado.**     

<img src="../../figures/even_k_ex1.png" alt="Exemplo 2 de k par" width="300"/>


## Melhor valor de k
Tendo em vista os poss√≠veis problemas decorrentes da escolha de k, √© essencial definir um valor em que ele que n√£o seja t√£o sens√≠vel aos seus vizinhos ao ponto de n√£o conseguir generalizar, mas tamb√©m n√£o seja extremamente abrangente ao ponto de ignorar padr√µes relevantes. Al√©m disso, optar por um valor √≠mpar de k √© igualmente essencial, a fim de evitar poss√≠veis empates ao analisar a maioria dos vizinhos mais pr√≥ximos.

Uma estrat√©gia comum para a escolha de k √© utilizar a raiz quadrada do n√∫mero total de dados do conjunto, pois n√£o ser√° um valor t√£o pequeno para ocasionar overfitting, mas nem t√£o grande para gerar underfitting. Caso o valor obtido seja par, √© indicado ajust√°-lo para o valor √≠mpar pr√≥ximo, a fim de evitar empates. Al√©m disso, o uso de valida√ß√£o cruzada √© recomendado para auxiliar na escolha do valor ideal de k, pois permite avaliar previamente os piores valores de k, evitando overfitting e underfitting.

<details>
  <summary><strong>O que s√£o t√©cnicas de valida√ß√£o de cruzada?</strong></summary>
  T√©cnicas de valida√ß√£o cruzadas consistem em dividir os dados em N partes menores, com um valor espec√≠fico de k. O modelo √© treinado em N-1 partes e testado na parte restante, repetindo esse processo N vezes, utilizando cada parte como conjunto de teste uma vez. A efici√™ncia do modelo √©, ent√£o, calculada com base na m√©dia de desempenho de todas as execu√ß√µes. O mesmo procedimento √© refeito para diferentes valores de k. O valor de k que apresentar a melhor m√©dia de desempenho √© o escolhido.
</details>

### Refer√™ncias
**IBM.** _K-nearest neighbors (KNN)_. Dispon√≠vel em: https://www.ibm.com/think/topics/knn. Acesso em: 21 de abril de 2025.
**FERREIRA, E.** _Cross-Validation_. Universidade Federal do Paran√°. Dispon√≠vel em: http://www.leg.ufpr.br/~eferreira/CE064/ency-cross-validation.pdf. Acesso em: 27 de abril de 2025.
**MARIZ, Filipe Mendes.** _Avalia√ß√£o e compara√ß√£o de vers√µes modificadas do algoritmo KNN_. 2017. [s.l.], Universidade Federal de Pernambuco, Centro de Inform√°tica, 2017. Dispon√≠vel em: https://www.cin.ufpe.br/~tg/2017-2/fmm4-tg.pdf. Acesso em: 23 de abril de 2025.
**SINGH, Manjeet; SINGH, Gurpreet.** _A Survey of kNN Algorithm_. 2018. Dispon√≠vel em: https://www.researchgate.net/publication/348305327_A_Survey_of_kNN_Algorithm. Acesso em: 23 de abril de 2025.

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | 
| :---: |