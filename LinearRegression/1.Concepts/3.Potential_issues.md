# English version

## Potential issues
When training a Linear Regression model with a specific dataset, many problems may arise. The most common ones are:

***1. Non-linearity of the data***

&nbsp;&nbsp;&nbsp;&nbsp; The linear regression model assumes that there is a strong relationship between the predictors and the response. If this relationship is very different from linear, it is concluded that the model cannot capture the true relationship, leading to inaccurate predictions and incorrect conclusions, significantly reducing its accuracy.

&nbsp;&nbsp;&nbsp;&nbsp; Residual plots are a great tool for identifying the nonlinearity of the model, as one can plot the residuals $e_i = y_i - \hat{y}_i$ versus the predictor $x_i$. In the case of many models, with multiple predictors, the predicted values $\hat{y}_i$ should be used.
   
   <img src="https://i.postimg.cc/sDCh8zQb/Captura-de-tela-2025-04-03-105017.png" alt="nonlinearity-of-the-data" width="300">
   
&nbsp;&nbsp;&nbsp;&nbsp; The figure above shows a residual plot using a linear regression model. The red line represents a smooth fit of the residuals and aims to facilitate the identification of trends. It is noted to exhibit a U-shape, indicating a lack of standardization of the residuals, suggesting nonlinearity in the data.
   
***2. Correlation of error terms***

&nbsp;&nbsp;&nbsp;&nbsp; An important deduction to be made about linear regression models is that error terms $e_1, e_2, ..., e_n$ are not correlated. If correlation exists among errors, the standard errors estimated for regression coefficients will tend to underestimate the true standard errors. For example, an 80% confidence interval may have a much lower probability than 0.8 of containing the true parameter value. Furthermore, this may result in lower p-values, leading to undue confidence in the model and incorrect conclusions regarding whether a parameter is statistically significant.
   
***3. Heteroscedasticity***

&nbsp;&nbsp;&nbsp;&nbsp; An important assumption is that error terms have a constant variance $Var(e_i) = \sigma^2$, meaning they are uniformly distributed across all observations. When heteroscedasticity occurs, it means the variance is not constant. Thus, the dispersion of residuals may vary depending on the values of the predictor variables or other conditions in the model.

   <img src="https://i.postimg.cc/NML6gxBV/Captura-de-tela-2025-04-03-144532.png" alt="nonlinearity-of-the-data" width="400">
   
&nbsp;&nbsp;&nbsp;&nbsp; Left: Funnel shape indicates heteroscedasticity. 

&nbsp;&nbsp;&nbsp;&nbsp;Right: The response was transformed to a logarithmic scale, and now there is no evidence of heteroscedasticity.
   
***4. Outliers***

&nbsp;&nbsp;&nbsp;&nbsp; An outlier is a point that significantly deviates from the value predicted by the model.

   <img src="https://i.postimg.cc/QCL1D9SZ/Captura-de-tela-2025-04-03-135113.png" alt="nonlinearity-of-the-data" width="300">

&nbsp;&nbsp;&nbsp;&nbsp; In the figure above, the residual plot on the left clearly shows the outlier (20). However, it may be difficult to determine when a point should be considered an outlier or not. Even though mathematical definitions and criteria exist to identify outliers (such as values above 3 and standard deviations), the decision may depend on the application context, the nature of the data, and the model used.

> ### Observation
>
> The residual plot mentioned in the topics above is a tool used to assess the quality of the model fit. It plots the residuals (differences between observed and predicted values) against the fitted values. The presence of evident patterns, such as clusters or trends, indicates problems with the model.

### Reference

This project utilizes concepts and techniques described in the book "An Introduction to Statistical Learning" (James et al., 2013).

# Portuguese version

## Problemas Potenciais

Quando se treina um modelo de Regressão Linear com um dataset em particular, muitos problemas podem ocorrer. Os mais comuns são:

***1.Não Linearidade dos dados***

&nbsp;&nbsp;&nbsp;&nbsp; O modelo de regressão linear assume que há uma forte relação entre os preditores e a resposta. Se essa relação for muito diferente de linear, conclui-se que o modelo não pode capturar a verdadeira relação, o que leva a previsões imprecisas e conclusões equivocadas, reduzindo consideravelmente sua precisão.

&nbsp;&nbsp;&nbsp;&nbsp; Os gráficos de resíduos são uma ótima ferramenta para identificar a não linearidade do modelo, pois é possível plotar os resíduos $e_i = y_i - \hat{y}_i$ em relação ao preditor $x_i$. No caso de modelos com muitos preditores, deve-se utilizar os valores previstos $\hat{y}_i$.

<img src="https://i.postimg.cc/sDCh8zQb/Captura-de-tela-2025-04-03-105017.png" alt="nonlinearity-of-the-data" width="300">

&nbsp;&nbsp;&nbsp;&nbsp; A figura acima exibe um gráfico de resíduos gerado com um modelo de regressão linear. A linha vermelha representa um ajuste suave dos resíduos e tem como objetivo facilitar a identificação de tendências. Nota-se que ela exibe um formato em "U", indicando uma falta de padronização nos resíduos e sugerindo a presença de não linearidade nos dados.

***2.Correlação dos termos de erro***

&nbsp;&nbsp;&nbsp;&nbsp; Uma importante observação a ser feita sobre modelos de regressão linear é que os termos de erro $e_1, e_2, ..., e_n$ não devem ser correlacionados. Caso exista correlação entre os erros, os erros padrão estimados para os coeficientes de regressão tendem a subestimar os valores reais. Por exemplo, um intervalo de confiança de 80% pode ter uma probabilidade muito menor do que 0,8 de conter o valor verdadeiro do parâmetro. Além disso, isso pode resultar em p-valores mais baixos, gerando uma confiança indevida no modelo e conclusões equivocadas sobre se um parâmetro é estatisticamente significativo.

***3.Heterocedasticidade***

&nbsp;&nbsp;&nbsp;&nbsp; Uma suposição importante é que os termos de erro possuem variância constante $Var(e_i) = \sigma^2$, ou seja, que são distribuídos de forma uniforme ao longo de todas as observações. Quando ocorre heterocedasticidade, a variância não é constante. Nesse caso, a dispersão dos resíduos pode variar dependendo dos valores das variáveis preditoras ou de outras condições do modelo.

<img src="https://i.postimg.cc/NML6gxBV/Captura-de-tela-2025-04-03-144532.png" alt="nonlinearity-of-the-data" width="400">
   
&nbsp;&nbsp;&nbsp;&nbsp; Esquerda: Um formato de funil indica heterocedasticidade.

&nbsp;&nbsp;&nbsp;&nbsp; Direita: Após transformar a resposta em logaritmo, não há mais evidências de heterocedasticidade.

***4.Outliers (Pontos Atípicos)***

&nbsp;&nbsp;&nbsp;&nbsp; Um outlier é um ponto que se desvia significativamente do valor previsto pelo modelo.

<img src="https://i.postimg.cc/QCL1D9SZ/Captura-de-tela-2025-04-03-135113.png" alt="nonlinearity-of-the-data" width="300">

&nbsp;&nbsp;&nbsp;&nbsp; Na figura acima, o gráfico de resíduos do lado esquerdo mostra claramente um outlier (20). No entanto, pode ser difícil determinar quando um ponto deve ser considerado um outlier. Embora existam definições matemáticas e critérios para identificá-los (como valores superiores a 3 desvios padrão), a decisão pode depender do contexto da aplicação, da natureza dos dados e do modelo utilizado.

> ### Observação
>
> O gráfico de resíduos mencionado nos tópicos acima é uma ferramenta utilizada para avaliar a qualidade do ajuste do modelo. Ele traça os resíduos (diferenças entre os valores observados e previstos) em relação aos valores ajustados. A presença de padrões evidentes, como clusters ou tendências, indica problemas no modelo.

### Referência

Este projeto utiliza conceitos e técnicas descritos no livro "An Introduction to Statistical Learning" (James et al., 2013).
