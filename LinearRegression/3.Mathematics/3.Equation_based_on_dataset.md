# English version

## How to find the simple linear regression equation based on a dataset
As previously explained in [1.General_representation_of_linear_regression.md](./1.General_representation_of_linear_regression.md), the simple linear regression can be represented by the equation of a straight line: 

$$
\hat{y} = \beta_0 + \beta_1 x
$$

The values Œ≤‚ÇÅ and Œ≤‚ÇÄ are unknown parameters, where Œ≤‚ÇÅ represents the slope of the line and Œ≤‚ÇÄ represents the y-intercept.

Therefore, to determine the values of Œ≤‚ÇÅ and Œ≤‚ÇÄ, we must first collect all training data and organize it into pairs of coordinates (x, y). Ultimately, we will have a set of coordinates as represented below:

$$
\(x1, y1), (x2, y2),..., (xn, yn)
$$

Where n represents the total number of data points collected. 

As explained in [2.The_least_squares_method.md](./2.The_least_squares_method.md), we can calculate the values of $\hat{\beta_1}$ and $\hat{\beta_0}$ using the equations below:

$$
\hat{\beta_1} = \frac{\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} )}{\sum_{i = 1}^{n} ( x_i - \bar{x} )^2}
$$

$$
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1\bar{X}
$$

- $x_i$: x values of each coordinate
- $y_i$: y values of each coordinate
- xÃÑ: simple arithmetic mean of the x values 
- yÃÑ: simple arithmetic mean of the y values

## Example

From one of the coding examples, let's analyze the relationship between hours studied and grades of a student.

| Hours Studied | Exam Score |
|--------------|------------|
| 1.5          | 50         |
| 3.0          | 55         |
| 4.5          | 65         |
| 6.0          | 70         |
| 7.5          | 80         |
| 9.0          | 85         |

Based on the data shown in the table above, we can calculate the values of Œ≤‚ÇÅ and Œ≤‚ÇÄ and define the equation of the line. For this purpose, we will define Hours Studied as x values and Exam Scores as y values. Thus, organizing all the data into pairs of coordinates, we will have the following points: (1.5, 50), (3.0, 55), (4.5, 65), (6.0, 70), (7.5, 80), (9.0, 85).

To facilitate the development of the Œ≤‚ÇÅ calculation, we will compute the variables and the summations independently, as exemplified below:

- xÃÑ = (1.5 + 3.0 + 4.5 + 6.0 + 7.5 + 9.0)/6 = 5.25
- yÃÑ =(50 + 55 + 65 + 70 + 80 + 85)/6 = 67.5
  
$$
\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} ) = (1.5 - 5.25)(50 - 67.5) + (3.0 - 5.25)(55 - 67.5) + (4.5 - 5.25)(65 -  67.5) + (6.0 - 5.25)(70 - 67.5) + (7.5 - 5.25)(80 - 67.5) + (9.0 - 5.25)(85 - 67.5) = 191.25
$$

$$
\sum_{i = 1}^{n} ( x_i - \bar{x} )^2 = (1.5 - 5.25)^2 + (3.0 - 5.25)^2 + (4.5 - 5.25)^2 + (6.0 - 5.25)^2 + (7.5 - 5.25)^2 + (9.0 - 5.25)^2 = 39.375
$$

By substituting the values into the original equation, we will arrive at:

$$
\hat{\beta}_1 = \frac{191.25}{39.375} = 4.85
$$

With the preceding steps completed, we are now able to calculate the value of Œ≤‚ÇÄ, as indicated below:

$$
\hat{\beta}_0 = 67.5 - 4.85*5.25 = 42.03
$$

Upon substitution of the Œ≤‚ÇÅ and Œ≤‚ÇÄ values into the linear equation, the following expression is obtained:

$$
\hat{y} = 42.05 + 4.85 x
$$

### Least Squares Error Calculation for the Exam Score Example

The least squares error \( S \) is calculated as:

$$
S = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

#### Step 1: Calculate Predicted Values ($(\hat{y}_i$\))

For each $x_i$, compute $\hat{y}_i$:

- $x = 1.5$: $\hat{y} = 42.05 + 4.85 \times 1.5 = 49.325$
- $x = 3.0$: $\hat{y} = 42.05 + 4.85 \times 3.0 = 56.6$
- $x = 4.5$: $\hat{y} = 42.05 + 4.85 \times 4.5 = 63.875$
- $x = 6.0$: $\hat{y} = 42.05 + 4.85 \times 6.0 = 71.15$
- $x = 7.5$: $\hat{y} = 42.05 + 4.85 \times 7.5 = 78.425$
- $x = 9.0$: $\hat{y} = 42.05 + 4.85 \times 9.0 = 85.7$

#### Step 2: Compute Differences (( y_i - $\hat{y}_i$\))

Subtract the predicted values from the observed values:

- \( 50 - 49.325 = 0.675 \)
- \( 55 - 56.6 = -1.6 \)
- \( 65 - 63.875 = 1.125 \)
- \( 70 - 71.15 = -1.15 \)
- \( 80 - 78.425 = 1.575 \)
- \( 85 - 85.7 = -0.7 \)

#### Step 3: Square the Differences

Square each difference:

- \( (0.675)^2 = 0.455625 \)
- \( (-1.6)^2 = 2.56 \)
- \( (1.125)^2 = 1.265625 \)
- \( (-1.15)^2 = 1.3225 \)
- \( (1.575)^2 = 2.480625 \)
- \( (-0.7)^2 = 0.49 \)

#### Step 4: Sum the Squared Differences

Add the squared differences to find \( S \):

$$
S = 0.455625 + 2.56 + 1.265625 + 1.3225 + 2.480625 + 0.49 = 8.574375
$$

#### Result

The least squares error for this model is approximately **8.57**.


## References
Universidade Federal do Rio Grande do Sul. (n.d.). Probabilidade e Estat√≠stica. Retrieved March 30, 2025, from https://www.ufrgs.br/probabilidade-estatistica/livro/livro_completo/ch7-reg-simples.html

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. An introduction to statistical learning. 2009.

Weisberg, S. Applied linear regression (4th ed.). Wiley. Retrieved March 30, 2025, from https://www.stat.purdue.edu/~qfsong/teaching/525/book/Weisberg-Applied-Linear-Regression-Wiley.pdf

## Where am I?

```text
RepoAI/
‚îî‚îÄ‚îÄ Linear Regression/
    ‚îú‚îÄ‚îÄ 1.Concepts/
    ‚îÇ   ‚îî‚îÄ‚îÄ Figures/
    ‚îÇ   ‚îî‚îÄ‚îÄ 1.History.md
    |   ‚îî‚îÄ‚îÄ 2.Typical_problems.md
    |   ‚îî‚îÄ‚îÄ 3.Potential_issues.md
    |   ‚îî‚îÄ‚îÄ 4.Fields_of_use.md
    ‚îú‚îÄ‚îÄ 2.Code/
    |   ‚îî‚îÄ‚îÄ Figures/
    |   ‚îî‚îÄ‚îÄ 1.Dive_into_the_docs.md  
    |   ‚îî‚îÄ‚îÄ 2.Boston_housing_price_reg.md
    |   ‚îî‚îÄ‚îÄ 3.Student_study_hours_prediction.md
    ‚îî‚îÄ‚îÄ 3.Mathematics/
    |   ‚îî‚îÄ‚îÄ Figures/
    |   ‚îî‚îÄ‚îÄ 1.General_representation_of_linear_regression.md 
    |   ‚îî‚îÄ‚îÄ 2.The_least_square_method.md 
    |   ‚îî‚îÄ‚îÄ 3.Equation_based_on_dataset.md   <---- You are here!!
```

## üëæ **Contributors**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) |  [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/105316221?v=4" width=115><br><sub>Vin√≠cius Muchulski</sub>](https://github.com/vini-muchulski) | 
| :---: | :---: | :---: | :---: |

## **License**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modify, and share at will! ‚úåÔ∏è

# Portuguese version

## Como encontrar a equa√ß√£o com base em um conjunto de dados

Como explicado anteriormente em [1.General_representation_of_linear_regression.md](./1.General_representation_of_linear_regression.md), a regress√£o linear simples pode ser representada por uma reta:

$$
\hat{y} = \beta_0 + \beta_1 x
$$

Os valores Œ≤‚ÇÅ and Œ≤‚ÇÄ s√£o par√¢metros desconhecidos, enquanto Œ≤‚ÇÅ representa a inclina√ß√£o da reta e Œ≤‚ÇÄ representa a intersec√ß√£o com o eixo y.

Portanto, para determinar os valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ, devemos primeiro coletar todos os dados de treinamento e organiz√°-los em pares de coordenadas (x, y). No final, teremos um conjunto de coordenadas assim como representado abaixo:

$$
\(x1, y1), (x2, y2),..., (xn, yn)
$$

Em que n representa o n√∫mero total de ponto de dados coletados. Enfim, podemos calcular os valores Œ≤1 e Œ≤0 utilizando as duas equa√ß√µes abaixo:

As explained in [2.The_least_squares_method.md](./2.The_least_squares_method.md), we can calculate the values of $\hat{\beta_1}$ and $\hat{\beta_0}$ using the equations below:

$$
\hat{\beta_1} = \frac{\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} )}{\sum_{i = 1}^{n} ( x_i - \bar{x} )^2}
$$

$$
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1\bar{X}
$$

- $x_i$: x values of each coordinate
- $y_i$: y values of each coordinate
- xÃÑ: simple arithmetic mean of the x values 
- yÃÑ: simple arithmetic mean of the y values

## Exemplo

A partir de um dos exemplos de c√≥digo, vamos analisar a rela√ß√£o entre horas de estudo e notas de um aluno.

| Hours Studied | Exam Score |
|--------------|------------|
| 1.5          | 50         |
| 3.0          | 55         |
| 4.5          | 65         |
| 6.0          | 70         |
| 7.5          | 80         |
| 9.0          | 85         |

Com base nos dados mostrados na tabela acima, podemos calcular os valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ e definir a equa√ß√£o da reta. Para isso, definiremos Horas de Estudo como valores x e Notas do Exame como valores y. Assim, organizando todos os dados em pares de coordenadas, teremos os seguintes pontos: (1.5, 50), (3.0, 55), (4.5, 65), (6.0, 70), (7.5, 80), (9.0, 85).

Para facilitar o desenvolvimento do c√°lculo de Œ≤‚ÇÅ, calcularemos as vari√°veis e os somat√≥rios separadamente, conforme exemplificado abaixo:

- xÃÑ = (1.5 + 3.0 + 4.5 + 6.0 + 7.5 + 9.0)/6 = 5.25
- yÃÑ =(50 + 55 + 65 + 70 + 80 + 85)/6 = 67.5
  
$$
\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} ) = (1.5 - 5.25)(50 - 67.5) + (3.0 - 5.25)(55 - 67.5) + (4.5 - 5.25)(65 - 67.5) + (6.0 - 5.25)(70 - 67.5) + (7.5 - 5.25)(80 - 67.5) + (9.0 - 5.25)(85 - 67.5) = 191.25
$$

$$
\sum_{i = 1}^{n} ( x_i - \bar{x} )^2 = (1.5 - 5.25)^2 + (3.0 - 5.25)^2 + (4.5 - 5.25)^2 + (6.0 - 5.25)^2 + (7.5 - 5.25)^2 + (9.0 - 5.25)^2 = 39.375
$$

Substituindo os valores na equa√ß√£o original, chegaremos a:

$$
\hat{\beta}_1 = \frac{191.25}{39.375} = 4.85
$$

Com os passos anteriores conclu√≠dos, agora podemos calcular o valor de Œ≤‚ÇÄ, conforme indicado abaixo:

$$
\hat{\beta}_0 = 67.5 - 4.85*5.25 = 42.03
$$

Ap√≥s a substitui√ß√£o dos valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ na equa√ß√£o linear, a seguinte express√£o √© obtida:

$$
\hat{y} = 42.05 + 4.85 x
$$

### M√©todo dos m√≠nimos quadrados para o exemplo

A soma dos m√≠nimos quadrados \( S \) √© calculada como:

$$
S = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

#### Passo 1: Calcular valores previstos ($(\hat{y}_i$\))

Para cada $x_i$, computar $\hat{y}_i$:

- $x = 1.5$: $\hat{y} = 42.05 + 4.85 \times 1.5 = 49.325$
- $x = 3.0$: $\hat{y} = 42.05 + 4.85 \times 3.0 = 56.6$
- $x = 4.5$: $\hat{y} = 42.05 + 4.85 \times 4.5 = 63.875$
- $x = 6.0$: $\hat{y} = 42.05 + 4.85 \times 6.0 = 71.15$
- $x = 7.5$: $\hat{y} = 42.05 + 4.85 \times 7.5 = 78.425$
- $x = 9.0$: $\hat{y} = 42.05 + 4.85 \times 9.0 = 85.7$

#### Passo 2: Calcular a diferen√ßa (( y_i - $\hat{y}_i$\))

- \( 50 - 49.325 = 0.675 \)
- \( 55 - 56.6 = -1.6 \)
- \( 65 - 63.875 = 1.125 \)
- \( 70 - 71.15 = -1.15 \)
- \( 80 - 78.425 = 1.575 \)
- \( 85 - 85.7 = -0.7 \)

#### Passo 3: Fazer a diferen√ßa ao quadrado

- \( (0.675)^2 = 0.455625 \)
- \( (-1.6)^2 = 2.56 \)
- \( (1.125)^2 = 1.265625 \)
- \( (-1.15)^2 = 1.3225 \)
- \( (1.575)^2 = 2.480625 \)
- \( (-0.7)^2 = 0.49 \)

#### Passo 4: Somar os quadrados das diferen√ßas

$$
S = 0.455625 + 2.56 + 1.265625 + 1.3225 + 2.480625 + 0.49 = 8.574375
$$

#### Resultado

O erro dos m√≠nimos quadrados para este modelo √© aproximadamente **8.57**.

## Refer√™ncias
Universidade Federal do Rio Grande do Sul. (n.d.). Probabilidade e Estat√≠stica. Retrieved March 30, 2025, from https://www.ufrgs.br/probabilidade-estatistica/livro/livro_completo/ch7-reg-simples.html

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. An introduction to statistical learning. 2009.

Weisberg, S. Applied linear regression (4th ed.). Wiley. Retrieved March 30, 2025, from https://www.stat.purdue.edu/~qfsong/teaching/525/book/Weisberg-Applied-Linear-Regression-Wiley.pdf

## Onde estou?

```text
RepoAI/
‚îî‚îÄ‚îÄ Linear Regression/
    ‚îú‚îÄ‚îÄ 1.Concepts/
    ‚îÇ   ‚îî‚îÄ‚îÄ Figures/
    ‚îÇ   ‚îî‚îÄ‚îÄ 1.History.md
    |   ‚îî‚îÄ‚îÄ 2.Typical_problems.md
    |   ‚îî‚îÄ‚îÄ 3.Potential_issues.md
    |   ‚îî‚îÄ‚îÄ 4.Fields_of_use.md
    ‚îú‚îÄ‚îÄ 2.Code/
    |   ‚îî‚îÄ‚îÄ Figures/
    |   ‚îî‚îÄ‚îÄ 1.Dive_into_the_docs.md  
    |   ‚îî‚îÄ‚îÄ 2.Boston_housing_price_reg.md
    |   ‚îî‚îÄ‚îÄ 3.Student_study_hours_prediction.md
    ‚îî‚îÄ‚îÄ 3.Mathematics/
    |   ‚îî‚îÄ‚îÄ Figures/
    |   ‚îî‚îÄ‚îÄ 1.General_representation_of_linear_regression.md 
    |   ‚îî‚îÄ‚îÄ 2.The_least_square_method.md 
    |   ‚îî‚îÄ‚îÄ 3.Equation_based_on_dataset.md   <---- Voc√™ est√° aqui!!
```

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) |  [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/105316221?v=4" width=115><br><sub>Vin√≠cius Muchulski</sub>](https://github.com/vini-muchulski) | 
| :---: | :---: | :---: | :---: |

## **Licen√ßa**  
[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://pt.wikipedia.org/wiki/Licen%C3%A7a_MIT)  
**Traslation:** Use, modifique e compartilhe √† vontade! ‚úåÔ∏è
