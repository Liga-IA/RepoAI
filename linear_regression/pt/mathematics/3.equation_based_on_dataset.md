
## Como encontrar a equa√ß√£o com base em um conjunto de dados

Como explicado anteriormente em [1.general_representation_of_linear_regression.md](./1.general_representation_of_linear_regression.md), a regress√£o linear simples pode ser representada por uma reta:

$$
\hat{y} = \beta_0 + \beta_1 x
$$

Os valores Œ≤‚ÇÅ and Œ≤‚ÇÄ s√£o par√¢metros desconhecidos, enquanto Œ≤‚ÇÅ representa a inclina√ß√£o da reta e Œ≤‚ÇÄ representa a intersec√ß√£o com o eixo y.

Portanto, para determinar os valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ, devemos primeiro coletar todos os dados de treinamento e organiz√°-los em pares de coordenadas (x, y). No final, teremos um conjunto de coordenadas assim como representado abaixo:

$$
\(x1, y1), (x2, y2),..., (xn, yn)
$$

Em que n representa o n√∫mero total de ponto de dados coletados. Enfim, podemos calcular os valores Œ≤1 e Œ≤0 utilizando as duas equa√ß√µes abaixo:

As explained in [2.the_least_squares_method.md](./2.the_least_squares_method.md), we can calculate the values of $\hat{\beta_1}$ and $\hat{\beta_0}$ using the equations below:

$$
\hat{\beta_1} = \frac{\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} )}{\sum_{i = 1}^{n} ( x_i - \bar{x} )^2}
$$

$$
\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1\bar{X}
$$

- $x_i$: x values of each coordinate
- $y_i$: y values of each coordinate
- xÃÑ: simple arithmetic mean of the x values 
- yÃÑ: simple arithmetic mean of the y values

## Exemplo

A partir de um dos exemplos de c√≥digo, vamos analisar a rela√ß√£o entre horas de estudo e notas de um aluno.

| Hours Studied | Exam Score |
|--------------|------------|
| 1.5          | 50         |
| 3.0          | 55         |
| 4.5          | 65         |
| 6.0          | 70         |
| 7.5          | 80         |
| 9.0          | 85         |

Com base nos dados mostrados na tabela acima, podemos calcular os valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ e definir a equa√ß√£o da reta. Para isso, definiremos Horas de Estudo como valores x e Notas do Exame como valores y. Assim, organizando todos os dados em pares de coordenadas, teremos os seguintes pontos: (1.5, 50), (3.0, 55), (4.5, 65), (6.0, 70), (7.5, 80), (9.0, 85).

Para facilitar o desenvolvimento do c√°lculo de Œ≤‚ÇÅ, calcularemos as vari√°veis e os somat√≥rios separadamente, conforme exemplificado abaixo:

- xÃÑ = (1.5 + 3.0 + 4.5 + 6.0 + 7.5 + 9.0)/6 = 5.25
- yÃÑ =(50 + 55 + 65 + 70 + 80 + 85)/6 = 67.5
  
$$
\sum_{i = 1}^{n} (x_i ‚Äì \bar{x} ) ( y_i ‚Äì \bar{y} ) = (1.5 - 5.25)(50 - 67.5) + (3.0 - 5.25)(55 - 67.5) + (4.5 - 5.25)(65 - 67.5) + (6.0 - 5.25)(70 - 67.5) + (7.5 - 5.25)(80 - 67.5) + (9.0 - 5.25)(85 - 67.5) = 191.25
$$

$$
\sum_{i = 1}^{n} ( x_i - \bar{x} )^2 = (1.5 - 5.25)^2 + (3.0 - 5.25)^2 + (4.5 - 5.25)^2 + (6.0 - 5.25)^2 + (7.5 - 5.25)^2 + (9.0 - 5.25)^2 = 39.375
$$

Substituindo os valores na equa√ß√£o original, chegaremos a:

$$
\hat{\beta}_1 = \frac{191.25}{39.375} = 4.85
$$

Com os passos anteriores conclu√≠dos, agora podemos calcular o valor de Œ≤‚ÇÄ, conforme indicado abaixo:

$$
\hat{\beta}_0 = 67.5 - 4.85*5.25 = 42.03
$$

Ap√≥s a substitui√ß√£o dos valores de Œ≤‚ÇÅ e Œ≤‚ÇÄ na equa√ß√£o linear, a seguinte express√£o √© obtida:

$$
\hat{y} = 42.05 + 4.85 x
$$

### M√©todo dos m√≠nimos quadrados para o exemplo

A soma dos m√≠nimos quadrados \( S \) √© calculada como:

$$
S = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

#### Passo 1: Calcular valores previstos ($(\hat{y}_i$\))

Para cada $x_i$, computar $\hat{y}_i$:

- $x = 1.5$: $\hat{y} = 42.05 + 4.85 \times 1.5 = 49.325$
- $x = 3.0$: $\hat{y} = 42.05 + 4.85 \times 3.0 = 56.6$
- $x = 4.5$: $\hat{y} = 42.05 + 4.85 \times 4.5 = 63.875$
- $x = 6.0$: $\hat{y} = 42.05 + 4.85 \times 6.0 = 71.15$
- $x = 7.5$: $\hat{y} = 42.05 + 4.85 \times 7.5 = 78.425$
- $x = 9.0$: $\hat{y} = 42.05 + 4.85 \times 9.0 = 85.7$

#### Passo 2: Calcular a diferen√ßa (( y_i - $\hat{y}_i$\))

- \( 50 - 49.325 = 0.675 \)
- \( 55 - 56.6 = -1.6 \)
- \( 65 - 63.875 = 1.125 \)
- \( 70 - 71.15 = -1.15 \)
- \( 80 - 78.425 = 1.575 \)
- \( 85 - 85.7 = -0.7 \)

#### Passo 3: Fazer a diferen√ßa ao quadrado

- \( (0.675)^2 = 0.455625 \)
- \( (-1.6)^2 = 2.56 \)
- \( (1.125)^2 = 1.265625 \)
- \( (-1.15)^2 = 1.3225 \)
- \( (1.575)^2 = 2.480625 \)
- \( (-0.7)^2 = 0.49 \)

#### Passo 4: Somar os quadrados das diferen√ßas

$$
S = 0.455625 + 2.56 + 1.265625 + 1.3225 + 2.480625 + 0.49 = 8.574375
$$

#### Resultado

O erro dos m√≠nimos quadrados para este modelo √© aproximadamente **8.57**.

## Refer√™ncias
Universidade Federal do Rio Grande do Sul. (n.d.). Probabilidade e Estat√≠stica. Retrieved March 30, 2025, from https://www.ufrgs.br/probabilidade-estatistica/livro/livro_completo/ch7-reg-simples.html

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. An introduction to statistical learning. 2009.

Weisberg, S. Applied linear regression (4th ed.). Wiley. Retrieved March 30, 2025, from https://www.stat.purdue.edu/~qfsong/teaching/525/book/Weisberg-Applied-Linear-Regression-Wiley.pdf

## üëæ **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) |  [<img loading="lazy" src="https://avatars.githubusercontent.com/u/197432407?v=4" width=115><br><sub>Beatriz Schuelter Tartare</sub>](https://github.com/beastartare) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/178849007?v=4" width=115><br><sub>Rafaela Savaris</sub>](https://github.com/rafasavaris) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/105316221?v=4" width=115><br><sub>Vin√≠cius Muchulski</sub>](https://github.com/vini-muchulski) | 
| :---: | :---: | :---: | :---: |