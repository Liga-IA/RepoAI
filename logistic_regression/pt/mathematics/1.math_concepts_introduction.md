# Regress√£o Log√≠stica em Resumo üöÄ

<div align="center">
  <img src="../../figures/RL.png" alt="logistic-summary-banner" width="1000">
</div>

- **Objetivo**  
  Estimar a probabilidade de um resultado bin√°rio $y\in {0,1}$ passando um escore linear pela fun√ß√£o **sigmoide** (log√≠stica).

- **Como Funciona**
  
  Calcular

  $$P(y=1 \mid x) = \sigma({\theta}^T x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}}$$
  
  depois classificar utilizando o limiar em 0.5.
---
## **√çndice**

1. [Gloss√°rio de Termos-Chave](#gloss√°rio-de-termos-chave)  
2. [O que √© Regress√£o Log√≠stica?](#o-que-√©-regress√£o-log√≠stica)  
3. [Estimativa de M√°xima Verossimilhan√ßa](#estimativa-de-m√°xima-verossimilhan√ßa)  
4. [Fun√ß√£o de Custo Convexa](#fun√ß√£o-de-custo-convexa)  
5. [Fronteira de Decis√£o & Interpreta√ß√£o](#fronteira-de-decis√£o--interpreta√ß√£o)  
6. [Regulariza√ß√£o)](#regulariza√ß√£o) 
7. [Refer√™ncias Finais](#refer√™ncias-finais)
8. [Contribuidores](#contribuidores)

---
## Gloss√°rio de Termos-Chave

- **Fun√ß√£o Sigmoide (Log√≠stica)**  
  Uma curva suave em forma de S definida como $\sigma(z) = \frac{1}{1 + e^{-z}}$, que mapeia qualquer n√∫mero real para o intervalo (0,1). Representa a sa√≠da probabil√≠stica do modelo de regress√£o log√≠stica. F√°cil, n√£o √©?

- **Hip√≥tese**  
  Denotada $h_{\boldsymbol\theta}(x)$, √© a probabilidade prevista pelo modelo de que o resultado $y=1$ dado a entrada $x$. Na regress√£o log√≠stica, √© igual a $\sigma(\boldsymbol\theta^T x)$.

- **Odds (Chance Relativa)**  
  A raz√£o $\frac{P(y=1)}{P(y=0)}$, que expressa qu√£o mais prov√°vel √© o resultado positivo em compara√ß√£o ao negativo.

- **Log-Odds (Logito)**  
  O logaritmo natural das odds. Na regress√£o log√≠stica, o logito √© modelado como uma fun√ß√£o linear da entrada:
    
  $$\log\frac{P(y=1\mid x)}{P(y=0\mid x)} = \boldsymbol\theta^T x$$

  O logito mostra como o logaritmo das chances de um evento muda para cada altera√ß√£o unit√°ria em uma vari√°vel, fornecendo uma medida linear de efeito; por exemplo, se o coeficiente de logito de um modelo para ‚Äúhoras estudadas‚Äù √© 0.4, ent√£o cada hora extra aumenta o logito de aprova√ß√£o em 0.4; de forma equivalente, as odds de aprova√ß√£o s√£o multiplicadas por $\exp{0.4} = 1.49$ (um aumento de $49\%$).

- **Estimativa de M√°xima Verossimilhan√ßa (MLE)**  
  Um m√©todo estat√≠stico usado para estimar os par√¢metros $\boldsymbol\theta$ de um modelo maximizando a fun√ß√£o de verossimilhan√ßa, ou seja, a probabilidade de observar os dados fornecidos. Na regress√£o log√≠stica, o MLE ajusta os coeficientes $\theta$ para maximizar as probabilidades previstas das classes corretas, por exemplo, ajustando um modelo para prever se um e-mail √© spam maximizando a verossimilhan√ßa das etiquetas corretas dadas as palavras de entrada.

- **Gradiente**  
  Um vetor de derivadas parciais de uma fun√ß√£o em rela√ß√£o aos seus par√¢metros. Indica a dire√ß√£o de maior aumento e √© usado para otimizar o modelo via subida ou descida do gradiente.

- **Fun√ß√£o de Custo (Log-Loss)**  
  A log-verossimilhan√ßa negativa m√©dia sobre o conjunto de dados. Mede a diferen√ßa entre probabilidades previstas e resultados reais. Na regress√£o log√≠stica, √© convexa, garantindo um √∫nico m√≠nimo global. Essa convexidade significa que algoritmos de otimiza√ß√£o como descida do gradiente n√£o ficam presos em m√≠nimos locais ruins ‚Äî eles s√£o garantidos de encontrar a melhor solu√ß√£o poss√≠vel dentro do espa√ßo de par√¢metros.
  
  $$J(\boldsymbol\theta) = -\frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \log\left(h_{\boldsymbol\theta}(\mathbf{x}^{(i)})\right) + \left(1 - y^{(i)}\right) \log\left(1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})\right) \right]$$

  onde
  - $m$ √© o n√∫mero de exemplos de treino
  - $y^i \in 0,1$ √© o r√≥tulo verdadeiro
  - $h_{\theta}(x^i)$ √© a probabilidade prevista de que $y=1$
  - $\theta$ s√£o os par√¢metros do modelo  
  O custo aumenta abruptamente quando o modelo est√° confiante e errado, e √© minimizado quando as probabilidades previstas coincidem com os resultados reais.

- **Convexidade**  
  Uma propriedade das fun√ß√µes em que qualquer m√≠nimo local tamb√©m √© um m√≠nimo global. Fun√ß√µes de custo convexas tornam a otimiza√ß√£o confi√°vel e est√°vel.

- **Fronteira de Decis√£o**  
  A superf√≠cie onde a probabilidade prevista √© exatamente 0.5. Na regress√£o log√≠stica, essa fronteira √© linear e definida por $\boldsymbol\theta^T x = 0$.

- **Regulariza√ß√£o (L1 / L2)**  
  T√©cnicas usadas para evitar overfitting adicionando uma penalidade √† fun√ß√£o de custo:  
  - L1 (Lasso): adiciona $\sum |\theta_j|$  
  - L2 (Ridge): adiciona $\sum \theta_j^2$  

- **Deviance (Desvio)**  
  Uma medida de qu√£o bem o modelo se ajusta aos dados, definida como o dobro da diferen√ßa entre a log-verossimilhan√ßa de um modelo saturado (ajuste perfeito) e o modelo atual.

  $$D = 2 \left( \ell_{\text{saturated}} - \ell_{\text{model}} \right)$$
  
  onde
  - $\ell_{\text{saturated}}$‚Äã √© a log-verossimilhan√ßa do modelo saturado
  - $\ell_{\text{model}}$ √© a log-verossimilhan√ßa do modelo ajustado atual

- **Pseudo- $R^2$**  
  An√°logo √† m√©trica $R^2$ da regress√£o linear. Variantes comuns incluem Cox‚ÄìSnell e McFadden, usadas para avaliar o poder explicativo de modelos log√≠sticos.

  McFadden

    $$R^2_{\mathrm{McF}} = 1 - \frac{\ell_{\mathrm{full}}}{\ell_{0}}$$
    - $\ell_{0}$ log-verossimilhan√ßa do modelo nulo (apenas intercepto)
    - $\ell_{\mathrm{full}}$ log-verossimilhan√ßa do modelo ajustado

  O pseudo- $R^2$ de McFadden mede a melhora proporcional na log-verossimilhan√ßa do modelo ajustado em rela√ß√£o ao modelo nulo. Valores mais pr√≥ximos de 1 indicam melhor ajuste, embora valores t√≠picos sejam muito menores que o $R^2$ linear.

- **Regress√£o Log√≠stica Multiclasse**  
  Extens√µes da regress√£o log√≠stica para lidar com mais de duas classes, seja ajustando m√∫ltiplos classificadores bin√°rios (um-contra-o-resto) ou usando o modelo log√≠stico multinomial.

- **Fun√ß√£o Softmax**  
  Uma generaliza√ß√£o da fun√ß√£o sigmoide para classifica√ß√£o multiclasse. Transforma um vetor de escores reais em uma distribui√ß√£o de probabilidade sobre m√∫ltiplas classes:
  
  $\mathrm{softmax}(z_k) = \frac{e^{z_k}}{\sum_{j=1}^K e^{z_j}}$
---
> [!WARNING]
> N√£o se empolgue demais, foi s√≥ o primeiro aperto de m√£o.
---

## O que √© Regress√£o Log√≠stica?

A regress√£o log√≠stica √© um **algoritmo de classifica√ß√£o** usado para prever a probabilidade de um resultado bin√°rio (por exemplo, sucesso/fracasso, spam/n√£o spam, doen√ßa/n√£o doen√ßa) com base em uma ou mais vari√°veis de entrada.
---

### A Fun√ß√£o Log√≠stica:
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

Onde:
- $\(z = \boldsymbol\theta^T \mathbf{x}\)$ √© uma combina√ß√£o linear das vari√°veis de entrada e dos par√¢metros do modelo.
- A fun√ß√£o $\(\sigma(z)\)$ mapeia qualquer n√∫mero real para um valor entre 0 e 1, representando uma probabilidade.

---

### Interpreta√ß√£o:

- Se $\(\sigma(z) \approx 1\)$, o modelo prev√™ fortemente a classe 1.
- Se $\(\sigma(z) \approx 0\)$, o modelo prev√™ fortemente a classe 0.
- Se $\(\sigma(z) \approx 0.5\)$, o modelo est√° incerto.

---

### Log√≠stica vs. Linear

| Caracter√≠stica   | Regress√£o Linear                   | Regress√£o Log√≠stica                          |
|------------------|------------------------------------|----------------------------------------------|
| Intervalo da Sa√≠da | \((-\infty, \infty)\)            | \((0, 1)\)                                   |
| Usado Para       | Predi√ß√£o de resultados cont√≠nuos   | Classifica√ß√£o bin√°ria                        |
| Regra de Decis√£o | Limiar sobre o valor previsto      | Limiar sobre a probabilidade \(P(y=1)\)      |
| Fun√ß√£o de Custo  | Erro Quadr√°tico M√©dio (MSE)        | Log-Loss (Entropia Cruzada)                  |

---

## Estimativa de M√°xima Verossimilhan√ßa

A regress√£o log√≠stica √© tipicamente treinada via **estimativa de m√°xima verossimilhan√ßa (MLE)**, que busca o vetor de par√¢metros $\( \boldsymbol\theta \)$ que **maximiza a probabilidade** de observar os dados.

> [!WARNING]
> Se os par√¢metros $\theta$ ($\beta_0$ e $\beta_1$) pudessem ser estimados pelo m√©todo OLS, por que dever√≠amos usar o m√©todo MLE? 

---
### Primeiro: MLE para regress√£o linear comum (erro Gaussiano)

Imagine que voc√™ tenha uma regress√£o linear padr√£o:  

$$y = \theta_0 + \theta_1 x + \epsilon,\quad \epsilon \sim \mathcal{N}(0, \sigma^2)$$ 

O que isso significa? Para cada valor de $\(x\)$, o $\(y\)$ observado √© uma vari√°vel aleat√≥ria normalmente distribu√≠da em torno de $\(\theta_0 + \theta_1 x\)$.

<div align="center">
  <img src="../../figures/erro_distr.png" alt="logistic-summary-banner" width="1000">
</div>


Assim, a fun√ß√£o de verossimilhan√ßa (a probabilidade de observar os dados dados os par√¢metros) √©:  

$$L(\theta) \;=\; \prod_{i=1}^m \frac{1}{\sqrt{2\pi\sigma^2}}
\exp\Biggl(-\frac{\bigl(y^{(i)} - \theta^T x^{(i)}\bigr)^2}{2\sigma^2}\Biggr)$$

Tomando o log (porque maximizar a log-verossimilhan√ßa √© mais f√°cil que maximizar o produto) obtemos:  

$$\log L(\theta) = -\frac{m}{2}\,\log\bigl(2\pi\sigma^2\bigr) - \frac{1}{2\sigma^2}\sum_{i=1}^m\bigl(y^{(i)} - \theta^T x^{(i)}\bigr)^2$$

Note que:
- $\(-\tfrac{m}{2}\log(2\pi\sigma^2)\)$ √© constante em $\(\theta\)$,
- o √∫nico termo dependente de $\(\theta\)$ √© $\(-\tfrac{1}{2\sigma^2}\sum (y^{(i)} - \theta^T x^{(i)})^2\)$.

Maximizar isso em rela√ß√£o a \(\theta\) √©, portanto, equivalente a minimizar  

$$\sum_{i=1}^m \bigl(y^{(i)} - \theta^T x^{(i)}\bigr)^2$$

#### **Resultado:** MLE sob erro Gaussiano √© equivalente ao M√≠nimos Quadrados Ordin√°rios (OLS).  
O $\(\theta\)$ que maximiza a verossimilhan√ßa √© o mesmo que minimiza a soma dos res√≠duos quadrados.

---
### Segundo: O que muda na regress√£o log√≠stica?

Na regress√£o log√≠stica, as suposi√ß√µes diferem:

1. **Resultados bin√°rios.**  
   Agora $\(y \in \{0,1\}\)$, n√£o cont√≠nuo.

2. **Distribui√ß√£o de Bernoulli.**  
   Em vez de ru√≠do Gaussiano, assume-se  

   $$p = \sigma(\theta^T x),\quad \sigma(z)=\frac{1}{1+e^{-z}},$$
     
   de modo que  

   $$P(y=1 \mid x) = \sigma(\theta^T x),\quad
   P(y=0 \mid x) = 1 - \sigma(\theta^T x).$$

4. **Fun√ß√£o de verossimilhan√ßa.**  

   $$L(\theta)
   = \prod_{i=1}^m \Bigl[\sigma(\theta^T x^{(i)})\Bigr]^{y^{(i)}}
     \Bigl[1 - \sigma(\theta^T x^{(i)})\Bigr]^{1 - y^{(i)}}.$$

5. **Log-verossimilhan√ßa.**  
   
   $$\log L(\theta) = \sum_{i=1}^m \bigl[y^{(i)}\log(\sigma(\theta^T x^{(i)})) + (1 - y^{(i)})\log\bigl(1 - \sigma(\theta^T x^{(i)}))\bigr].$$

Essa fun√ß√£o **n√£o √© quadr√°tica** em $\(\theta\)$, e a sigmoide $\(\sigma(\theta^T x)\)$ √© uma fun√ß√£o **n√£o linear**.

#### **Resultado:**  
- N√£o existe **solu√ß√£o em forma fechada** como $\(\theta = (X^TX)^{-1}X^Ty\)$.  
- √â preciso resolver $\(\theta\)$ **iterativamente** (ex.: gradiente descendente, m√©todo de Newton).

---

### Resumo

|                                | Regress√£o Linear   | Regress√£o Log√≠stica   |
|--------------------------------|---------------------------------|-------------------------------------|
| **Fun√ß√£o de verossimilhan√ßa**  | Gaussiana                       | Bernoulli                           |
| **Forma da equa√ß√£o**           | Quadr√°tica (parab√≥lica)          | N√£o linear (sigmoidal)              |
| **M√©todo de solu√ß√£o**          | Forma fechada (MQO)              | Otimiza√ß√£o iterativa                |
| **MQO = MVE?**                 | Sim                              | N√£o                                 |

---

### Fun√ß√£o de Verossimilhan√ßa

Dado um conjunto de dados com $\( m \)$ amostras independentes $\( \{(\mathbf{x}^{(i)}, y^{(i)})\}_{i=1}^m \)$, a verossimilhan√ßa √© o produto das probabilidades:

$$L(\boldsymbol\theta) = \prod_{i=1}^m \left[h_{\boldsymbol\theta}(\mathbf{x}^{(i)})\right]^{y^{(i)}} \left[1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})\right]^{1 - y^{(i)}}$$

Essa formula√ß√£o combina a probabilidade de $\( y=1 \)$ e $\( y=0 \)$ em uma √∫nica express√£o usando expoentes.

---

### Fun√ß√£o de Log-Verossimilhan√ßa

Como o produto pode ser numericamente inst√°vel, trabalha-se com a **log-verossimilhan√ßa**:

$$\ell(\boldsymbol\theta) = \sum_{i=1}^m \left[ y^{(i)} \ln h_{\boldsymbol\theta}(\mathbf{x}^{(i)}) + (1 - y^{(i)}) \ln(1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})) \right]$$

Maximizar essa log-verossimilhan√ßa √© equivalente a encontrar os par√¢metros que melhor se ajustam ao modelo log√≠stico.

---

### Gradiente para Otimiza√ß√£o

Para otimizar $\( \ell(\boldsymbol\theta) \)$, calcula-se o gradiente:

$$\nabla_{\boldsymbol\theta}\,\ell(\boldsymbol\theta) = \sum_{i=1}^m \left( y^{(i)} - h_{\boldsymbol\theta}(\mathbf{x}^{(i)}) \right) \mathbf{x}^{(i)}$$

Essa express√£o √© usada no **gradiente ascendente**, em que cada atualiza√ß√£o caminha na dire√ß√£o do gradiente:

$$\boldsymbol\theta := \boldsymbol\theta + \alpha \nabla_{\boldsymbol\theta}\,\ell(\boldsymbol\theta)$$

Alternativamente, se minimizarmos a **log-verossimilhan√ßa negativa**, usamos o gradiente **descendente**.

---

### Interpreta√ß√£o

- A log-verossimilhan√ßa captura o ajuste do modelo aos r√≥tulos observados.  
- Cada amostra contribui com um termo ponderado por sua probabilidade no modelo.  
- O gradiente reflete o **erro** entre predi√ß√£o e r√≥tulo.

> [!TIP]
> O MVE garante que escolhemos os par√¢metros que melhor explicam os dados sob as suposi√ß√µes do modelo log√≠stico.

---

## Fun√ß√£o de Custo Convexa

Na regress√£o log√≠stica, a fun√ß√£o de custo (tamb√©m chamada de **log-loss** ou **entropia cruzada**) √© convexa. Isso significa que existe um √∫nico m√≠nimo global, o que garante que t√©cnicas de otimiza√ß√£o como gradiente descendente convergem para a solu√ß√£o √≥tima.

A fun√ß√£o de custo log-loss para regress√£o log√≠stica √© definida como:

$$J(\boldsymbol\theta) = - \frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \ln h_{\boldsymbol\theta}(\mathbf{x}^{(i)}) + (1 - y^{(i)}) \ln(1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})) \right]$$

Como a fun√ß√£o √© convexa, o gradiente descendente pode encontrar de forma confi√°vel os melhores par√¢metros $\(\boldsymbol\theta\)$ que minimizam a fun√ß√£o de custo.

---

## Fronteira de Decis√£o & Interpreta√ß√£o

A **fronteira de decis√£o** na regress√£o log√≠stica √© a superf√≠cie onde o modelo tem probabilidade igual de prever classe 0 ou classe 1. Em outras palavras, √© onde a probabilidade prevista √© 0,5. Matematicamente, isso ocorre quando:

$$\sigma(\boldsymbol\theta^T \mathbf{x}) = 0.5$$

Resolvendo para $\( \mathbf{x} \)$, encontramos que a fronteira de decis√£o ocorre quando:

$$\boldsymbol\theta^T \mathbf{x} = 0$$

Isso significa que a fronteira de decis√£o √© uma fun√ß√£o linear das vari√°veis de entrada. Para um conjunto de dados 2D, a fronteira √© uma linha reta, e em dimens√µes maiores, um hiperplano.

### Interpreta√ß√£o:
- **Coeficientes**: A magnitude de cada coeficiente $\(\theta_j\)$ representa o quanto a vari√°vel $\(x_j\)$ influencia a predi√ß√£o do modelo. Uma magnitude maior indica maior impacto.  
- **Raz√£o de Chances (Odds Ratio)**: A raz√£o de chances para uma vari√°vel √© dada por $\(\exp(\theta_j)\)$, que indica como as chances do desfecho mudam quando a vari√°vel aumenta em uma unidade.

---

## Regulariza√ß√£o

Para evitar overfitting, aplica-se frequentemente **regulariza√ß√£o** em modelos de regress√£o log√≠stica. A regulariza√ß√£o penaliza coeficientes grandes, for√ßando o modelo a usar apenas as vari√°veis mais relevantes.

- **Regulariza√ß√£o L1 (Lasso)**: Adiciona uma penalidade igual ao valor absoluto dos coeficientes:

  $$J(\boldsymbol\theta) = - \frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \ln h_{\boldsymbol\theta}(\mathbf{x}^{(i)}) + (1 - y^{(i)}) \ln(1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})) \right] + \lambda \sum_{j=1}^n |\theta_j|$$

  A regulariza√ß√£o L1 incentiva a **esparsidade**, ou seja, alguns coeficientes podem se tornar exatamente zero, realizando sele√ß√£o de vari√°veis.

- **Regulariza√ß√£o L2 (Ridge)**: Adiciona uma penalidade igual ao quadrado dos coeficientes:
  
  $$J(\boldsymbol\theta) = - \frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \ln h_{\boldsymbol\theta}(\mathbf{x}^{(i)}) + (1 - y^{(i)}) \ln(1 - h_{\boldsymbol\theta}(\mathbf{x}^{(i)})) \right] + \lambda \sum_{j=1}^n \theta_j^2$$

  A regulariza√ß√£o L2 desencoraja coeficientes grandes, mas n√£o necessariamente os zera, permitindo que todas as vari√°veis sejam inclu√≠das no modelo.

---

## Refer√™ncias Finais

- Brunner, E. (2011). *Logistic regression and related methods: Analysis of categorical data*. Springer.

- Cox, D. R. (1958). *The regression analysis of binary sequences*. Journal of the Royal Statistical Society: Series B (Methodological), 20(2), 215-242.

- Kunovich, S. (2015). *Statistical methods for binary classification*. Wiley.

- Agresti, A. (2018). *Statistical methods for the social sciences*. Pearson.

- Hosmer, D. W., & Lemeshow, S. (2000). *Applied logistic regression* (2nd ed.). Wiley-Interscience.

- McFadden, D. (1974). *Conditional logit analysis of qualitative choice behavior*. In P. Zarembka (Ed.), *Frontiers in econometrics* (pp. 105-142). Academic Press.

- Nelder, J. A., & Wedderburn, R. W. M. (1972). *Generalized linear models*. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.

---

## Resumo 
### A regress√£o log√≠stica √© um *modelo fundamental no aprendizado supervisionado*. √â matematicamente elegante, interpret√°vel e funciona bem como classificador de linha de base. Tamb√©m √© a *base de muitos modelos avan√ßados* como redes neurais.

---

## **Contribuidores**  
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/91793807?v=4" width=115><br><sub>√çtalo Silva</sub>](https://github.com/ITA-LOW) | 
| :---: |
