# Portuguese version

# Diferen√ßas entre Random Forest e √Årvores de Decis√£o Simples

## Robustez, Precis√£o e Generaliza√ß√£o

√Årvores de Decis√£o s√£o altamente sens√≠veis a pequenas varia√ß√µes nos dados de treinamento. Pequenas mudan√ßas podem levar a estruturas totalmente diferentes da √°rvore, tornando-as modelos inst√°veis com alto risco de sobreajuste (overfitting).

Random Forest, ao combinar v√°rias √°rvores independentes constru√≠das sobre subconjuntos diferentes dos dados e atributos, reduz essa instabilidade. Essa abordagem melhora a generaliza√ß√£o e robustez, ao suavizar erros individuais das √°rvores e aumentar a precis√£o m√©dia do modelo final.

---

## 2. Interpretabilidade vs Desempenho

√Årvores de Decis√£o s√£o consideradas modelos de caixa branca: suas regras s√£o f√°ceis de entender e visualizar. Isso facilita a explica√ß√£o do modelo para n√£o especialistas e a tomada de decis√µes com base em l√≥gica transparente.

Random Forest, por outro lado, √© considerada um modelo de caixa preta, pois agrega previs√µes de centenas (ou milhares) de √°rvores, o que dificulta a interpreta√ß√£o direta. Contudo, oferece desempenho superior na maioria dos cen√°rios pr√°ticos, especialmente em tarefas com muitos ru√≠dos ou alta dimensionalidade.

---

## 3. Varia√ß√£o entre modelos

√Årvore de Decis√£o √∫nica pode ter fronteiras de decis√£o muito irregulares, o que pode levar a overfitting. Mesmo pequenas rota√ß√µes nos dados podem impactar significativamente seu desempenho.

Random Forest cria m√∫ltiplas √°rvores com aleatoriedade tanto nos dados quanto nas vari√°veis escolhidas em cada divis√£o. Isso permite maior diversidade entre as √°rvores, e quando combinadas por vota√ß√£o majorit√°ria, produzem resultados mais suaves e confi√°veis.


## üëæ Colaboradores
|  [<img loading="lazy" src="https://avatars.githubusercontent.com/u/153019298?v=4" width=115><br><sub>Seidi Ducher</sub>](https://github.com/seidiDucher)  
| :---: |