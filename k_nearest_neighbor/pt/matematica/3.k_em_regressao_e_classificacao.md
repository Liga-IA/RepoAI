## "k" em Regressão e Classificação

Como explicado em [Como determinar o valor de k](../../pt/1.conceitos/3.como_determinar_valor_de_k.md), temos as seguintes características de k:
- k, quando pequeno, tende a gerar overfitting
- k, quando grande, tende a gerar underfitting
- k, quando par, pode gerar empates nos problemas de classificação e, consequentemente, imprecisões.

Ao escolhermos o melhor valor, podemos utilizar como ponto de partida a raiz quadrada do número de dados disponíveis. No entanto, uma forma mais assertiva para essa decisão é utilizar técnicas de validação cruzada!

Mas, agora, vamos entender melhor a matemática por trás dessas características!

Para entendermos se k é grande ou pequeno, precisamos abordar os conceitos de **erro**, **viés** e **variância**.

### Erro

Podemos calcular o erro produzido por um modelo de mais de uma forma. No entanto, aqui foi escolhida uma forma para regressão, e uma para classificação.

#### Erro em regressão
Para regressão, o erro total pode ser calculado por meio do "Erro Quadrático Médio", cuja fórmula é: 

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

Em que:
- $\text{MSE}$ é o erro quadrático médio (Mean Squared Error, em inglês)
- $n$ é o número total de amostras no conjunto de dados.  
- $y_i$ é o valor real observado da $i$-ésima amostra.  
- $\hat{y}_i$ é o valor predito pelo modelo para a $i$-ésima amostra.  
- $(y_i - \hat{y}_i)^2$ é o erro ao quadrado da $i$-ésima amostra, que penaliza mais fortemente discrepâncias maiores.  

#### Erro em classificação
Para classificação, podemos calcular a taxa de erro da seguinte maneira:

$$
\text{Taxa de Erro} = \frac{\text{Número de previsões incorretas}}{\text{Número total de amostras}}
$$

> [!NOTE]
> Em todos os modelos, não importa o quão bons eles sejam, sempre haverá um erro associado às previsões. Esse componente do erro, que não pode ser eliminado, é chamado de erro irredutível. As fórmulas anteriores calculam o erro total, que engloba - dentre outros fatores - o erro irredutível, como veremos mais adiante.

### Viés
É quando um modelo é um muito simples para captar o comportamento real dos dados.

Em regressão linear, por exemplo, seria como tentar representar um padrão curvo com uma reta.
No contexto de KNN, seria generalizar o modelo de tal forma que ele não capta padrões locais. Isto ocorre quando usamos valores de k muito grandes, já que está considerando muitos vizinhos para chegar a uma resposta.

**alto k** -> **alto viés** -> **underfitting**

> [!NOTE]
> Portanto, podemos entender o viés por meio do mesmo exemplo utilizado em "Underfitting e valores altos de k" na parte conceitual: [Como determinar o valor de k](../../pt/1.conceitos/3.como_determinar_valor_de_k.md).

### Variância
Se refere a quanto as previsões do modelo mudariam caso fosse treinado com outro conjunto de dados. 

Ou seja, quando há alta variância, se adicionarmos ou removermos um ponto, é possível que a predição mude drasticamente. Isto ocorre quando usamos valores de k muito pequenos, já que está considerando poucos vizinhos para chegar a uma resposta.

**baixo k** -> **alta variância** -> **overfitting**

> [!NOTE]
> Portanto, podemos entender a variância por meio do mesmo exemplo utilizado em "Overfitting e valores baixos de k" na parte conceitual: [Como determinar o valor de k](../../pt/1.conceitos/3.como_determinar_valor_de_k.md).

### Relação entre Erro, Viés e Variância

#### Regressão
É possível afirmar que, o MSE - isto é, o erro total - pode ser representado como:

$$
\text{Erro Total}=\text{Viés}^2+\text{Variância}+\text{Erro Irredutível}
$$

#### Classificação
A ideia de que há relação entre o erro total com o erro irredutível, viés e variância se mantém. No entanto, a decomposição do erro total em termos desses outros conceitos não é feita de forma tão direta.

>[!TIP]
> Para encontrarmos o melhor k, devemos encontrar o valor mínimo do erro total. Lembrando que, quando k aumenta:
> - O viés aumenta
> - A variância diminui
> - O erro irredutível permanece constante

## Validação cruzada
Para o cálculo mais preciso de k, utilizamos a validação cruzada.

Basicamente, quando avaliamos um modelo, calculamos o **erro de treinamento** (que é calculado com base nos dados utilizados para treinarmos o modelo), e, também, calculamos o **erro de teste** (que é calculado com base em novos dados).

Por isso, fazemos validação cruzada: 
1. Escolhemos um valor para k.
2. Dividimos os dados em subconjuntos.
3. Para o valor de k, treinamos os dados no subconjunto escolhido e testo nos que não foram escolhidos.
4. Calcula o erro para o k escolhido. Repete o processo até ter feito para vários valores de k.
5. Escolhe o k com base no que resultou em menor erro.

## Referências
JAMES, Gareth et al. An introduction to statistical learning: with applications in Python. New York: Springer, 2023.

HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. The elements of statistical learning: data mining, inference, and prediction. 2. ed. New York: Springer, 2009.

## Colaboradores
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/160762179?v=4" width=115><br><sub>Maria Eduarda Vianna</sub>](https://github.com/mevianna) | 
| :---: | 
